<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 第二十一章。异步编程

> 异步编程的常规方法的问题在于它们是要么全有要么全无的命题。你重写所有的代码，这样就不会阻塞，否则你只是在浪费时间。
> 
> 阿尔瓦罗·维德拉和杰森·j·w·威廉姆斯 *RabbitMQ 在行动* [1]

本章阐述了三个密切相关的主题:

*   Python 的`async def`、`await`、`async with`和`async for`构造

*   支持这些构造的对象:本机协同程序和上下文管理器、可迭代程序、生成器和理解的异步变体

*   *asyncio* 和其他异步库

本章基于可迭代程序和生成器(第 17 章，特别是“经典协程”)、上下文管理器(第 18 章)和并发编程的一般概念(第 19 章)。

我们将研究类似于我们在第 20 章中看到的那些并发 HTTP 客户端，用本地协程和异步上下文管理器重写，使用与以前相同的 *HTTPX* 库，但是现在通过它的异步 API。我们还将看到如何通过将缓慢的操作委派给线程或流程执行器来避免阻塞事件循环。

在 HTTP 客户端示例之后，我们将看到两个简单的异步服务器端应用程序，其中一个使用越来越流行的 *FastAPI* 框架。然后我们将讨论其他由`async/await`关键字支持的语言结构:异步生成器函数、异步理解和异步生成器表达式。为了强调这些语言特性与 *asyncio* 无关的事实，我们将看到一个使用 *Curio* 重写的例子 David Beazley 发明的优雅而创新的异步框架。

为了结束这一章，我写了一个关于异步编程的优点和缺陷的简短章节。

那是一个很大的范围。我们只有基本例子的空间，但它们将阐明每个想法最重要的特征。

###### 小费

Yury Selivanov[2]对 asyncio 文档进行了重新组织，将对应用程序开发人员有用的一些功能与针对 web 框架和数据库驱动程序等包的创建者的低级 API 分离开来，之后，asyncio 的文档要好得多。

关于 asyncio 的书籍篇幅，我推荐 Caleb Hattingh (O'Reilly)的 [*在 Python 中使用 Asyncio*](https://fpy.li/hattingh)。充分披露:凯勒是这本书的技术审查之一。

# 本章的新内容

当我写第一版 *Fluent Python* 的时候， *asyncio* 库是临时的，`async/await`关键字并不存在。因此，我不得不更新本章中的所有例子。我还创建了新的例子:域探测脚本、FastAPI web 服务和 Python 新的异步控制台模式的实验。

新的章节涵盖了当时并不存在的语言特性，比如原生协程、`async with`、`async for`，以及支持这些构造的对象。

“异步如何工作以及如何不工作”中的观点反映了我认为对于任何使用异步编程的人来说必不可少的经验教训。它们可能会为您省去很多麻烦——无论您使用的是 Python 还是 Node.js。

最后，我删除了几段关于`asyncio.Futures`的内容，它现在被认为是低级*asyncio*API 的一部分。

# 几个定义

在开始的“经典协程”中，我们看到 Python 3.5 和更高版本提供了三种协程:

Native coroutine

一个用`async def`定义的T42 协程函数。您可以使用`await`关键字从一个本机协同程序委托给另一个本机协同程序，类似于经典协同程序使用`yield from`的方式。`async def`语句总是定义一个本地协程，即使在其主体中没有使用`await`关键字。`await`关键字不能在本机协程之外使用。 [3]

Classic coroutine

使用通过`my_coro.send(data)`发送给它的数据的生成器函数调用，并通过在表达式中使用`yield`读取数据。经典协程可以使用`yield from`委托给其他经典协程。经典协程不能被`await`驱动，并且不再被 *asyncio* 支持。

Generator-based coroutine

一个用`@types.coroutine`修饰的 生成器函数——在 Python 3.5 中引入。那个装饰器使生成器与新的`await` 关键字兼容。

在这一章中，我们关注本地协同程序以及*异步生成器*:

Asynchronous generator

用`async def`定义的发生器功能，并在其主体中使用`yield`。它返回一个异步生成器对象，该对象提供了一个检索下一项的协程方法`__anext__`。

# @asyncio.coroutine 没有未来[4]

根据[问题 43216](https://fpy.li/21-2) ，经典协程和基于生成器的协程的 `@asyncio.coroutine`装饰器在 Python 3.8 中已被弃用，并计划在 Python 3.11 中移除。相反，根据[问题 36921](https://fpy.li/21-3) ，应该保留`@types.coroutine`。不再被 *asyncio* 支持，而是在 *Curio* 和 *Trio* 异步框架中的低级代码中使用。

# asyncio 示例:探测域

想象一下 你即将在 Python 上开一个新博客，你计划用 Python 关键字和*注册一个域名。DEV* 后缀—例如: *AWAIT.DEV.* 示例 21-1 是一个使用 *asyncio* 同时检查几个域的脚本。这是它产生的输出:

```
$ python3 blogdom.py
  with.dev
+ elif.dev
+ def.dev
  from.dev
  else.dev
  or.dev
  if.dev
  del.dev
+ as.dev
  none.dev
  pass.dev
  true.dev
+ in.dev
+ for.dev
+ is.dev
+ and.dev
+ try.dev
+ not.dev
```

请注意，域看起来是无序的。如果您运行该脚本，您会看到它们一个接一个地显示，延迟各不相同。`+`符号表示您的机器能够通过 DNS 解析域名。否则，该域无法解析，并且可能是可用的。[5]

在 *blogdom.py* 中，DNS 探测是通过本地协程对象完成的。因为异步操作是交叉进行的，所以检查 18 个域所需的时间比顺序检查要少得多。事实上，总时间实际上与单个最慢 DNS 响应的时间相同，而不是所有响应时间的总和。

示例 21-1 显示了 *blogdom.py* 的代码。

##### 示例 21-1：blogdom.py:搜索 Python 博客的域名

```
#!/usr/bin/env python3importasyncioimportsocketfromkeywordimportkwlistMAX_KEYWORD_LEN=4①asyncdefprobe(domain:str)->tuple[str,bool]:②loop=asyncio.get_running_loop()③try:awaitloop.getaddrinfo(domain,None)④exceptsocket.gaierror:return(domain,False)return(domain,True)asyncdefmain()->None:⑤names=(kwforkwinkwlistiflen(kw)<=MAX_KEYWORD_LEN)⑥domains=(f'{name}.dev'.lower()fornameinnames)⑦coros=[probe(domain)fordomainindomains]⑧forcoroinasyncio.as_completed(coros):⑨domain,found=awaitcoro⑩mark='+'iffoundelse''print(f'{mark}{domain}')if__name__=='__main__':asyncio.run(main())⑪
```

① 设置域名关键字的最大长度，因为越短越好。

② `probe`返回一个带有域名和一个布尔值的元组；`True`表示域名解析。返回域名将更容易显示结果。

③ 获取对`asyncio`事件循环的引用，这样我们接下来就可以使用它了。

④ [`loop.getaddrinfo(…)`](https://fpy.li/21-4) 协程方法返回一个[五部分参数元组](https://fpy.li/21-5)，以使用套接字连接到给定的地址。在这个例子中，我们不需要结果。如果我们得到了它，域名解析；否则，它不会。

⑤ `main`必须是协程，这样我们才能在里面用`await`。

⑥ 生成长度高达`MAX_KEYWORD_LEN`的 Python 关键字的生成器。

⑦ 生成带有`.dev`后缀的域名的生成器。

⑧ 通过使用每个`domain`参数调用`probe`协程来构建一个协程对象列表。

⑨ `asyncio.as_completed`是一个生成协程的生成器，它按照协程完成的顺序(而不是提交的顺序)返回传递给它的结果。类似于我们在第二十章、示例 20-4 中看到的`futures.as_completed`。

⑩ 此时，我们知道协程已经完成，因为这就是`as_completed`的工作方式。因此，`await`表达式不会被阻塞，但我们需要它从`coro`获得结果。如果`coro`引发了一个未处理的异常，它将在这里被重新引发。

⑪ `asyncio.run`启动事件循环，仅当事件循环退出时返回。对于使用`asyncio`的脚本来说，这是一种常见的模式:将`main`实现为协程，并在`if __name__ == '__main__':`块中用`asyncio.run`驱动它。

###### 小费

在 Python 3.7 中添加了用于协程内部的`asyncio.get_running_loop`函数，如`probe`所示。如果没有运行循环，`asyncio.get_running_loop`提高`RuntimeError`。它的实现比`asyncio.get_event_loop`更简单、更快，后者可能会在必要时启动一个事件循环。从 Python 3.10 开始，`asyncio.get_event_loop`被[弃用](https://fpy.li/21-6)，最终将成为`asyncio.get_running_loop`的别名。

## Guido 读取异步代码的技巧

在 *asyncio* 中有很多新的概念需要理解，但是如果你使用吉多·范·罗苏姆自己建议的一个技巧:眯眼假装`async`和`await`关键词不存在，那么示例 21-1 的整体逻辑很容易理解。如果你这样做了，你会发现协程读起来就像普通的顺序函数。

例如，想象这个协程的主体…

```
async def probe(domain: str) -> tuple[str, bool]:
    loop = asyncio.get_running_loop()
    try:
        await loop.getaddrinfo(domain, None)
    except socket.gaierror:
        return (domain, False)
    return (domain, True)
```

…工作方式类似于以下函数，除了它神奇地从不阻塞:

```
def probe(domain: str) -> tuple[str, bool]:  # no async
    loop = asyncio.get_running_loop()
    try:
        loop.getaddrinfo(domain, None)  # no await
    except socket.gaierror:
        return (domain, False)
    return (domain, True)
```

使用语法`await loop.getaddrinfo(...)`避免了阻塞，因为`await`挂起了当前的协程对象。例如，在执行`probe('if.dev')`协程期间，一个新的协程对象由`getaddrinfo('if.dev', None)`创建。等待它启动低级`addrinfo`查询，并将控制权交还给事件循环，而不是被挂起的`probe(‘if.dev’)`协程。然后，事件循环可以驱动其他挂起的协程对象，如`probe('or.dev')`。

当事件循环获得对`getaddrinfo('if.dev', None)`查询的响应时，特定的协程对象恢复并将控制返回给`probe('if.dev')`——在`await`暂停——现在可以处理可能的异常并返回结果元组。

到目前为止，我们只看到了应用于协程的`asyncio.as_completed`和`await`。但是它们处理任何合适的对象。接下来解释这个概念。

# 新概念:可盈利

`for`关键字与*可重复项*一起使用。`await`关键字适用于*候选人*。

作为 *asyncio* 的最终用户，这些是您每天都会看到的奖励:

*   一个*本机协程对象*，它是通过调用一个*本机协程函数*得到的

*   一个`asyncio.Task`，通常通过将协程对象传递给`asyncio.create_task()`来获得

然而，最终用户代码并不总是需要在`Task`上`await`。我们使用`asyncio.create_task(one_coro())`来调度`one_coro`进行并发执行，而不等待它的返回。这就是我们在 *spinner_async.py* 中对`spinner`协程所做的事情(示例 19-4 )。如果不期望取消任务或者等待任务，那么就没有必要保留从`create_task`返回的`Task`对象。创建任务足以调度协程运行。

相比之下，我们现在使用`await other_coro()`来运行`other_coro`并等待它完成，因为我们需要它的结果才能继续。在 *spinner_async.py* 中，`supervisor`协程执行`res = await slow()`来执行`slow`并得到其结果。

当实现异步库或对 asyncio 本身做出贡献时，您可能还会处理这些底层的可获得性:

*   带有返回迭代器的`__await__`方法的对象；例如，`asyncio.Future`实例(`asyncio.Task`是`asyncio.Future`的子类)

*   使用 Python/C API 和`tp_as_async.am_await`函数编写的对象，返回一个迭代器(类似于`__await__`方法)

现有的代码库也可能有一种额外的可用类型:*基于生成器的协程对象*——它们正在被弃用的过程中。

###### 注意

PEP 492 [声明](https://fpy.li/21-7)表达式`await`使用了`yield from`实现，并额外增加了一个验证其参数的步骤，并且`await`只接受一个 awaitablePEP 没有详细解释那个实现，但是参考了 [PEP 380](https://fpy.li/pep380) ，它引入了`yield from`。我在 fluentpython.com[](http://fluentpython.com)*的[【经典协程】](https://fpy.li/oldcoro)[【产出的意义】](https://fpy.li/21-8)一节贴了详细解释。*

 *现在让我们研究一下脚本的 asyncio 版本，它下载一组固定的旗帜图像。*  *# 使用 asyncio 和 HTTPX 下载

*flags _ asyncio . py*脚本从*fluentpython.com*下载一组固定的 20 个标志。我们最初在“并发网络下载”中提到它，但是现在我们将应用我们刚刚看到的概念来详细研究它。

从 Python 3.10 开始， *asyncio* 只直接支持 TCP 和 UDP，标准库中没有异步 HTTP 客户端或服务器包。我在所有的 HTTP 客户端示例中使用了 [*HTTPX*](https://fpy.li/httpx) 。

我们将从下向上探索*flags _ asyncio . py*——也就是说，首先看看示例 21-2 中设置动作的函数。

###### 警告

为了使代码更容易阅读， *flags_asyncio.py* 没有错误处理。当我们介绍`async/await`时，最初关注“快乐之路”是很有用的，可以理解程序中的常规函数和伴随式是如何排列的。从“增强 asyncio 下载器”开始，例子包括错误处理和更多特性。

*旗帜 _。py 本章的*示例和第 20 章共享代码和数据，因此我将它们放在 [*示例-code-2e/20-executors/getflags*](https://fpy.li/21-9)目录中。

##### 示例 21-2： flags_asyncio.py:启动功能

```
defdownload_many(cc_list:list[str])->int:①returnasyncio.run(supervisor(cc_list))②asyncdefsupervisor(cc_list:list[str])->int:asyncwithAsyncClient()asclient:③to_do=[download_one(client,cc)forccinsorted(cc_list)]④res=awaitasyncio.gather(*to_do)⑤returnlen(res)⑥if__name__=='__main__':main(download_many)
```

① 这需要是一个普通的函数，而不是一个伴随函数，所以它可以从 *flags.py* 模块传递给`main`函数并被其调用(示例 20-2 )。

② 执行驱动`supervisor(cc_list)`协同对象的事件循环，直到它返回。这将在事件循环运行时阻止。这条线的结果就是`supervisor`返回的任何值。

③ `httpx`中的异步 HTTP 客户端操作是`AsyncClient`的方法，T5 也是一个异步上下文管理器:一个具有异步设置和拆卸方法的上下文管理器(更多信息见“异步上下文管理器”)。

④ 通过为要检索的每个标志调用一次`download_one` coroutine，建立一个 coroutine 对象列表。

⑤ 等待`asyncio.gather` coroutine，它接受一个或多个可感知的参数并等待它们全部完成，按照提交的顺序返回给定可感知的结果列表。

⑥ `supervisor`返回`asyncio.gather`返回的列表长度。

现在我们来回顾一下 *flags_asyncio.py* 的顶部(示例 21-3 )。我重新组织了协程，这样我们就可以按照事件循环启动它们的顺序来读取它们。

##### 示例 21-3： flags_asyncio.py:导入和下载功能

```
importasynciofromhttpximportAsyncClient①fromflagsimportBASE_URL,save_flag,main②asyncdefdownload_one(client:AsyncClient,cc:str):③image=awaitget_flag(client,cc)save_flag(image,f'{cc}.gif')print(cc,end='',flush=True)returnccasyncdefget_flag(client:AsyncClient,cc:str)->bytes:④url=f'{BASE_URL}/{cc}/{cc}.gif'.lower()resp=awaitclient.get(url,timeout=6.1,follow_redirects=True)⑤returnresp.read()⑥
```

① 必须安装—它不在标准库中。

② 重用 *flags.py* 中的代码(示例 20-2 )。

③ `download_one`必须是本地协程，所以它可以在`get_flag`上`await`——它执行 HTTP 请求。然后显示下载的旗帜代码，并保存图像。

④ `get_flag`需要接收`AsyncClient`来发出请求。

⑤ 一个`httpx.AsyncClient`实例的`get`方法返回一个`ClientResponse`对象，它也是一个异步上下文管理器。

⑥ 网络 I/O 操作被实现为协程方法，因此它们由`asyncio`事件循环异步驱动。

###### 注意

为了获得更好的性能，`get_flag`中的`save_flag`调用应该是异步的，以避免阻塞事件循环。然而, *asyncio* 目前没有提供异步文件系统 API——node . js 提供了。

“使用 asyncio.as_completed 和一个线程”将展示如何将`save_flag`委托给一个线程。

您的代码通过`await`显式委托给`httpx`协程，或者通过异步上下文管理器的特殊方法隐式委托给`Async​Client`和`ClientResponse`——我们将在“异步上下文管理器”中看到。

## 原生协程的秘密:不起眼的生成器

我们在“经典协程”和 *flags_asyncio.py* 中看到的经典协程例子的一个关键区别是，后者中没有可见的`.send()`调用或`yield`表达式。你的代码位于 *asyncio* 库和你正在使用的异步库之间，比如 *HTTPX* 。图 21-1 中对此进行了说明。

![Await channel diagram](Images/flpy_2101.png)

###### 图 21-1。在异步程序中，用户函数启动事件循环，用`asyncio.run`调度初始协程。每个用户的协程用一个`await`表达式驱动下一个，形成一个通道，使像 *HTTPX* 这样的库和事件循环之间能够通信。

在幕后，`asyncio`事件循环进行`.send`调用，驱动您的协同程序，以及您的协同程序在其他协同程序上的`await`，包括库协同程序。如前所述，`await`借用了`yield from`的大部分实现，后者也调用`.send`来驱动协程。

`await`链最终到达一个低级的可调用对象，该对象返回一个生成器，事件循环可以驱动该生成器来响应诸如定时器或网络 I/O 之类的事件。这些`await`链末端的低级可调用对象和生成器是在库的深处实现的，不是它们的 API 的一部分，可能是 Python/C 扩展。

使用像`asyncio.gather`和`asyncio.create_task`这样的函数，您可以启动多个并发的`await`通道，在一个线程中实现由一个事件循环驱动的多个 I/O 操作的并发执行。

## 全有或全无的问题

注意，在示例 21-3 中，我无法重用 *flags.py* 中的`get_flag`函数(示例 20-2](ch20.xhtml#flags_module_ex) )。我不得不将它重写为一个协同程序，以使用 *HTTPX* 的异步 API。对于使用 *asyncio* 的峰值性能，我们必须将每个执行 I/O 的函数替换为使用`await`或`asyncio.create_task`激活的异步版本，以便在函数等待 I/O 时将控制权交还给事件循环。如果您不能将阻塞函数重写为协程，您应该在单独的线程或进程中运行它，正如我们将在[“将任务委派给执行者”中看到的。

这就是为什么我选择了这一章的题词，其中包含了这样的建议:“你重写所有的代码，这样就不会有任何代码阻塞，否则你就是在浪费时间。”

出于同样的原因，我也不能重用*flags _ thread pool . py*(示例 20-3](ch20.xhtml#flags_threadpool_ex) )中的`download_one`函数。[示例 21-3 中的代码用`await`驱动`get_flag`，所以`download_one`也一定是协程。对于每个请求，在`supervisor`中创建一个`download_one`协程对象，它们都由 `asyncio.gather` 协程驱动。

现在我们来研究一下`supervisor` ( 示例 21-2 )和`get_flag` ( 示例 21-3 )中出现的`async with`语句。

# 异步上下文管理器

在 “上下文管理器和 with 块”中，我们看到了如果一个对象的类提供了`__enter__`和`__exit__`方法，那么如何使用该对象在`with`块的主体之前和之后运行代码。

现在，考虑示例 21-4 ，来自[*asyncpg*](https://fpy.li/21-10)*asyncio*-兼容 PostgreSQL 驱动程序[的关于事务](https://fpy.li/21-11)的文档。

##### 示例 21-4：来自 *asyncpg* PostgreSQL 驱动程序文档的示例代码

```
tr = connection.transaction()
await tr.start()
try:
    await connection.execute("INSERT INTO mytable VALUES (1, 2, 3)")
except:
    await tr.rollback()
    raise
else:
    await tr.commit()
```

数据库事务非常适合上下文管理器协议:必须启动事务，使用`connection.execute`更改数据，然后必须进行回滚或提交，这取决于更改的结果。

在像 *asyncpg* 这样的异步驱动中，设置和总结需要是协同程序，以便其他操作可以同时发生。然而，经典的`with`语句的实现不支持协程做`__enter__`或`__exit__`的工作。

这就是为什么[PEP 492—带有 async 和 await 语法的协同程序](https://fpy.li/pep492)引入了`async with`语句，它与异步上下文管理器一起工作:将`__aenter__`和`__aexit__`方法实现为协同程序的对象。

有了`async with`，示例 21-4 可以写成来自 [*asyncpg* 文档](https://fpy.li/21-11)的另一个片段:

```
async with connection.transaction():
    await connection.execute("INSERT INTO mytable VALUES (1, 2, 3)")
```

在 [`asyncpg.Transaction`类](https://fpy.li/21-13)中，`__aenter__`协程方法执行`await self.start()`，而`__aexit__`协程等待私有`__rollback`或`__commit`协程方法，这取决于是否发生异常。使用协程将`Transaction`实现为异步上下文管理器允许 *asyncpg* 并发处理许多事务。

# asyncpg 上的 Caleb Hattingh

asyncpg 的另一个伟大之处在于，它还通过为 PostgreSQL 自身的内部连接实现一个连接池，解决了 PostgreSQL 缺乏高并发性支持的问题(每个连接使用一个服务器端进程)。

这意味着你不需要像 *asyncpg* 文档](https://fpy.li/21-14)中解释的 *pgbouncer* 这样的额外工具。 ^([6)

回到*flags _ asyncio . py*,`httpx`的`AsyncClient`类是一个异步上下文管理器，因此它可以在其`__aenter__`和`__aexit__`特殊协程方法中使用 awaitables。

###### 注意

“异步生成器作为上下文管理器”展示了如何使用 Python 的`contextlib`创建异步上下文管理器，而无需编写类。这个解释将在本章的后面给出，因为有一个先决主题:“异步生成器函数”。

我们现在将用一个进度条来增强 *asyncio* 标志下载示例，这将引导我们探索更多的 asyncio API。

# 增强 asyncio 下载器

回想一下“带进度显示和错误处理的下载”中的 ，这些`flags2`示例共享相同的命令行界面，它们在下载过程中显示进度条。它们还包括错误处理。

###### 小费

我鼓励您尝试一下`flags2`示例，以直观地了解并发 HTTP 客户端是如何执行的。使用`-h`选项查看示例 20-10 中的帮助屏幕。使用`-a`、`-e`和`-l`命令行选项控制下载数量，使用`-m`选项设置并发下载数量。对`LOCAL`、`REMOTE`、`DELAY`和`ERROR`服务器运行测试。发现并发下载的最佳数量，以最大化每台服务器的吞吐量。调整测试服务器的选项，如“设置测试服务器”所述。

例如，示例 21-5 显示了一个从`ERROR`服务器获取 100 个标志的尝试，使用了 100 个并发请求(`-m 100`)。结果中的 48 个错误要么是 HTTP 418，要么是超时错误——这是 *slow_server.py* 的预期(错误)行为。

##### 示例 21-5：运行标志 2_asyncio.py

```
$ python3 flags2_asyncio.py -s ERROR -al 100 -m 100
ERROR site: http://localhost:8002/flags
Searching for 100 flags: from AD to LK
100 concurrent connections will be used.
100%|█████████████████████████████████████████| 100/100 [00:03<00:00, 30.48it/s]
--------------------
 52 flags downloaded.
 48 errors.
Elapsed time: 3.31s
```

# 测试并发客户端时要负责任

即使线程客户端和 *asyncio* HTTP 客户端的整体下载时间相差不大， *asyncio* 也可以更快地发送请求，因此服务器更有可能怀疑 DoS 攻击。要真正全速运行这些并发客户端，请使用本地 HTTP 服务器进行测试，如“设置测试服务器”中所述。

现在我们来看看 *flags2_asyncio.py* 是如何实现的。

## 使用 asyncio.as_completed 和一个线程

在 示例 21-3 中，我们向`asyncio.gather`传递了几个协程，它返回了一个列表，按照提交的顺序列出了协程的结果。这意味着`asyncio.gather`只能在所有 awaitables 完成后返回。然而，要更新进度条，我们需要在完成时得到结果。

幸运的是，有一个`asyncio`等价于我们在带有进度条的线程池示例中使用的`as_completed`生成器函数(示例 20-16 )。

示例 21-6 显示了 *flags2_asyncio.py* 脚本的顶部，其中定义了`get_flag`和`download_one`协程。示例 21-7 列出了其余的来源，有`supervisor`和`download_many`。由于错误处理，该脚本比 *flags_asyncio.py* 长。

##### 示例 21-6： flags2_asyncio.py:脚本的顶部；其余代码在示例 21-7 中

```
importasynciofromcollectionsimportCounterfromhttpimportHTTPStatusfrompathlibimportPathimporthttpximporttqdm# type: ignorefromflags2_commonimportmain,DownloadStatus,save_flag# low concurrency default to avoid errors from remote site,# such as 503 - Service Temporarily UnavailableDEFAULT_CONCUR_REQ=5MAX_CONCUR_REQ=1000asyncdefget_flag(client:httpx.AsyncClient,①base_url:str,cc:str)->bytes:url=f'{base_url}/{cc}/{cc}.gif'.lower()resp=awaitclient.get(url,timeout=3.1,follow_redirects=True)②resp.raise_for_status()returnresp.contentasyncdefdownload_one(client:httpx.AsyncClient,cc:str,base_url:str,semaphore:asyncio.Semaphore,verbose:bool)->DownloadStatus:try:asyncwithsemaphore:③image=awaitget_flag(client,base_url,cc)excepthttpx.HTTPStatusErrorasexc:④res=exc.responseifres.status_code==HTTPStatus.NOT_FOUND:status=DownloadStatus.NOT_FOUNDmsg=f'not found: {res.url}'else:raiseelse:awaitasyncio.to_thread(save_flag,image,f'{cc}.gif')⑤status=DownloadStatus.OKmsg='OK'ifverboseandmsg:print(cc,msg)returnstatus
```

① `get_flag`与示例 20-14 中的顺序版本非常相似。第一个区别:它需要`client`参数。

② 第二个和第三个区别:`.get`是一个`AsyncClient`方法，它是一个协程，所以我们需要`await`它。

③ 使用`semaphore`作为异步上下文管理器，这样整个程序就不会被阻塞；当信号量计数器为零时，只有这个协程被挂起。更多关于这个的内容在《Python 的信号量》。

④ 错误处理逻辑与`download_one`中的相同，来自示例 20-14 。

⑤ 保存图像是一项 I/O 操作。为了避免阻塞事件循环，在线程中运行`save_flag`。

所有网络 I/O 都是通过 *asyncio* 中的协程完成的，而不是文件 I/O。但是，文件 I/O 也是的“阻塞”——从某种意义上说，读/写文件比读/写 RAM 花费的时间[要长几千倍](https://fpy.li/21-15)。如果您使用的是[网络附加存储](https://fpy.li/21-16)，它甚至可能涉及到幕后的网络 I/O。

从 Python 3.9 开始，`asyncio.to_thread`协程使得将文件 I/O 委托给由 *asyncio* 提供的线程池变得更加容易。如果你需要支持 Python 3.7 或 3.8，“将任务委派给执行者”展示了如何添加几行代码来实现。但是首先，让我们完成对 HTTP 客户端代码的学习。

## 用信号量限制请求

像我们正在研究的网络客户端 应该*节流*(即受限)以避免过多的并发请求冲击服务器。

一个 *信号量*](https://fpy.li/21-17) 是一个同步原语，比锁更灵活。一个信号量可以由多个协程持有，最大数量可以配置。这使得限制活动并发协程的数量变得非常理想。[“Python 的信号量”有更多信息。

在*flags 2 _ thread pool . py*(示例 20-16](ch20.xhtml#flags2_threadpool_full) )中，通过实例化`ThreadPoolExecutor`并在`download_many`函数中将所需的`max_workers`参数设置为`concur_req`来实现节流。在 *flags2_asyncio.py* 中，由`supervisor`函数创建一个`asyncio.Semaphore`(如[示例 21-7 所示)并作为`semaphore`参数传递给`download_one`示例 21-6 。

现在让我们看看示例 21-7 中的其余脚本。

##### 示例 21-7： flags2_asyncio.py:脚本上接示例 21-6

```
asyncdefsupervisor(cc_list:list[str],base_url:str,verbose:bool,concur_req:int)->Counter[DownloadStatus]:①counter:Counter[DownloadStatus]=Counter()semaphore=asyncio.Semaphore(concur_req)②asyncwithhttpx.AsyncClient()asclient:to_do=[download_one(client,cc,base_url,semaphore,verbose)forccinsorted(cc_list)]③to_do_iter=asyncio.as_completed(to_do)④ifnotverbose:to_do_iter=tqdm.tqdm(to_do_iter,total=len(cc_list))⑤error:httpx.HTTPError|None=None⑥forcorointo_do_iter:⑦try:status=awaitcoro⑧excepthttpx.HTTPStatusErrorasexc:error_msg='HTTP error {resp.status_code} - {resp.reason_phrase}'error_msg=error_msg.format(resp=exc.response)error=exc⑨excepthttpx.RequestErrorasexc:error_msg=f'{exc} {type(exc)}'.strip()error=exc⑩exceptKeyboardInterrupt:breakiferror:status=DownloadStatus.ERROR⑪ifverbose:url=str(error.request.url)⑫cc=Path(url).stem.upper()⑬print(f'{cc} error: {error_msg}')counter[status]+=1returncounterdefdownload_many(cc_list:list[str],base_url:str,verbose:bool,concur_req:int)->Counter[DownloadStatus]:coro=supervisor(cc_list,base_url,verbose,concur_req)counts=asyncio.run(coro)⑭returncountsif__name__=='__main__':main(download_many,DEFAULT_CONCUR_REQ,MAX_CONCUR_REQ)
```

① `supervisor`接受与`download_many`函数相同的参数，但是它不能直接从`main`调用，因为它是一个协程，而不是像`download_many`那样的普通函数。

② 创建一个`asyncio.Semaphore`，在使用这个信号量的进程中不允许超过`concur_req`个活动协程。`concur_req`的值由`main`函数从 *flags2_common.py* 中计算得出，基于命令行选项和每个示例中设置的常量。

③ 创建一个协程对象列表，每次调用`download_one`协程一个对象。

④ 获取一个迭代器，它将在完成时返回协程对象。我没有在下面的`for`循环中直接调用`as_completed`，因为我可能需要用进度条的`tqdm`迭代器来包装它，这取决于用户对详细程度的选择。

⑤ 用`tqdm`生成器函数包装`as_completed`迭代器，以显示进度。

⑥ 用`None`声明并初始化`error`；该变量将用于保存`try/except`语句之外的异常，如果出现异常的话。

⑦ 迭代完成的协程对象；该循环与示例 20-16 中`download_many`的循环相似。

⑧ `await`在协程上得到它的结果。这不会阻塞，因为`as_completed`只产生完成的协程。

⑨ 这个赋值是必要的，因为`exc`变量的作用域仅限于这个`except`子句，但是我需要为以后保留它的值。

⑩ 和以前一样。

⑪ 如果有错误，设置`status`。

⑫ 在详细模式下，从引发的异常中提取 URL

⑬ …然后提取文件名，接下来显示国家代码。

⑭ `download_many`实例化`supervisor`协程对象，并通过`asyncio.run`将其传递给事件循环，收集事件循环结束时计数器`supervisor`返回的值。

在示例 21-7 中，我们不能使用示例 20-16 中看到的期货到国家代码的映射，因为`asyncio.as_completed`返回的与我们传递到`as_completed`调用中的 awaitables 相同。从内部来说，asyncio,machine,可能会用其他最终会产生相同结果的东西来代替我们提供的奖励。 [8]

###### 小费

因为在失败的情况下，我不能使用 awaitables 作为键从`dict`中检索国家代码，所以我必须从异常中提取国家代码。为此，我将异常保存在`error`变量中，以便在`try/except`语句之外进行检索。Python 不是一种块范围的语言:像 loops 和`try/except`这样的语句不会在它们管理的块中创建局部范围。但是如果一个`except`子句将一个异常绑定到一个变量，就像我们刚刚看到的`exc`变量——这个绑定只存在于那个特定的`except`子句中的块内。

这就结束了对功能上等同于我们之前看到的 *flags2_threadpool.py* 的 *asyncio* 示例的讨论。

下一个例子演示了使用协程一个接一个地执行异步任务的简单模式。这值得我们注意，因为任何以前使用过 JavaScript 的人都知道，一个接一个地运行异步函数是嵌套编码模式的原因，这种模式被称为 [*末日金字塔*](https://fpy.li/21-20) 。关键字`await`让诅咒消失。这就是为什么`await`现在是 Python 和 JavaScript 的一部分。

## 为每次下载发出多个请求

假设您希望保存每个国家的国旗，包括国家名称和国家代码，而不仅仅是国家代码。现在，您需要为每个旗帜发出两个 HTTP 请求:一个请求获取旗帜图像本身，另一个请求获取与图像位于同一目录中的 *metadata.json* 文件——那里记录了国家的名称。

在线程脚本中，协调同一任务中的多个请求很容易:只需发出一个请求，然后发出另一个请求，阻塞线程两次，并将两部分数据(国家代码和名称)保存在本地变量中，以备保存文件时使用。如果您需要在带有回调的异步脚本中做同样的事情，那么您需要嵌套函数，以便在保存文件之前，国家代码和名称可以在它们的闭包中使用，因为每个回调都在不同的本地范围内运行。`await`关键字缓解了这种情况，允许您一个接一个地驱动异步请求，共享驱动协程的本地范围。

###### 小费

如果你正在用现代 Python 进行异步应用程序编程，并且有很多回调，你可能正在应用在现代 Python 中没有意义的旧模式。如果您正在编写一个与不支持协程的遗留或低级代码接口的库，这是合理的。反正stack overflowQ&A、[“future . add _ done _ callback()的用例是什么？”](https://fpy.li/21-21)解释为什么回调在低级代码中是需要的，但是在 Python 应用程序级代码中却不是很有用。

`asyncio`标志下载脚本的第三个变体有一些变化:

`get_country`

这个新的协程获取国家代码的 *metadata.json* 文件，并从中获取国家的名称。

`download_one`

这个协程现在使用`await`来委托给`get_flag`和新的`get_country`协程，使用后者的结果来构建要保存的文件名。

先说`get_country`的代码(示例 21-8 )。注意与示例 21-6 中的`get_flag`非常相似。

##### 示例 21-8： flags3_asyncio.py: `get_country`协程

```
asyncdefget_country(client:httpx.AsyncClient,base_url:str,cc:str)->str:①url=f'{base_url}/{cc}/metadata.json'.lower()resp=awaitclient.get(url,timeout=3.1,follow_redirects=True)resp.raise_for_status()metadata=resp.json()②returnmetadata['country']③
```

① 如果一切顺利，这个协程返回一个带有国家名称的字符串。

② `metadata`将从响应的 JSON 内容中获得一个 Python `dict`。

③ 返回国家名称。

现在我们来看示例 21-9 中修改后的`download_one`，它与示例 21-6 中的同一个协程只有几行代码的变化。

##### 示例 21-9： flags3_asyncio.py: `download_one`协程

```
asyncdefdownload_one(client:httpx.AsyncClient,cc:str,base_url:str,semaphore:asyncio.Semaphore,verbose:bool)->DownloadStatus:try:asyncwithsemaphore:①image=awaitget_flag(client,base_url,cc)asyncwithsemaphore:②country=awaitget_country(client,base_url,cc)excepthttpx.HTTPStatusErrorasexc:res=exc.responseifres.status_code==HTTPStatus.NOT_FOUND:status=DownloadStatus.NOT_FOUNDmsg=f'not found: {res.url}'else:raiseelse:filename=country.replace('','_')③awaitasyncio.to_thread(save_flag,image,f'{filename}.gif')status=DownloadStatus.OKmsg='OK'ifverboseandmsg:print(cc,msg)returnstatus
```

① 握住`semaphore`至`await`进行`get_flag` …

② …再一次为`get_country`。

③ 使用国家名称创建文件名。作为命令行用户，我不喜欢在文件名中看到空格。

比嵌套回调好多了！

我把对`get_flag`和`get_country`的调用放在由`semaphore`控制的单独的`with`块中，因为尽可能短时间地持有信号量和锁是一个好习惯。

我可以使用`asyncio.gather`并行调度`get_flag`和`get_country`，但是如果`get_flag`引发异常，就没有图像可以保存，所以运行`get_country`是没有意义的。但是有些情况下，使用`asyncio.gather`同时点击几个 API 是有意义的，而不是在发出下一个请求之前等待一个响应。

在 *flags3_asyncio.py* 中，`await`语法出现了六次，`async with`出现了三次。希望您能够掌握 Python 中异步编程的诀窍。一个挑战是知道什么时候必须使用`await`，什么时候不能使用。原则上，答案很简单:你`await`协程和其他可感知的东西，比如`asyncio.Task`实例。但是有些 API 很狡猾，以看似任意的方式混合了协程和普通函数，比如我们将在示例 21-14 中使用的`StreamWriter`类。

示例 21-9 包起*旗帜*套示例。现在让我们讨论异步编程中线程或进程执行器的使用。

# 将任务委派给执行者

对于异步编程，Node.js 优于 Python 的一个重要优势是 Node.js 标准库，它为所有 I/O 提供异步 API，而不仅仅是网络 I/O。在 Python 中，如果不小心，文件 I/O 会严重降低异步应用程序的性能，因为在主线程中读写存储会阻塞事件循环。

在示例 21-6 的`download_one`协程中，我使用了这一行将下载的镜像保存到磁盘:

```
        await asyncio.to_thread(save_flag, image, f'{cc}.gif')
```

如前所述，`asyncio.to_thread`是在 Python 3.9 中添加的。如果您需要支持 3.7 或 3.8，那么用示例 21-10 中的行替换该单行。

##### 示例 21-10：代替`await asyncio.to_thread`使用的行

```
loop=asyncio.get_running_loop()①loop.run_in_executor(None,save_flag,②image,f'{cc}.gif')③
```

① 获取对事件循环的引用。

② 第一个参数是要使用的执行者；传递`None`选择默认的`ThreadPoolExecutor`，它在`asyncio`事件循环中总是可用的。

③ 你可以将位置参数传递给要运行的函数，但是如果你需要传递关键字参数，那么你需要求助于`functool.partial`，如 [`run_in_executor`文档](https://fpy.li/21-22)中所述。

新的`asyncio.to_thread`函数更容易使用，也更灵活，因为它也接受关键字参数。

`asyncio`的实现本身在少数地方使用了引擎盖下的`run_in_executor`。例如，我们在示例 21-1 中看到的`loop.getaddrinfo(…)`协程是通过从`socket`模块调用`getaddrinfo`函数来实现的——这是一个阻塞函数，可能需要几秒钟才能返回，因为它取决于 DNS 解析。

异步 API 中的一个常见模式是在内部使用`run_in_executor`包装阻塞调用，这是协程中的实现细节。这样，您就提供了一个由`await`驱动的一致的协程接口，并隐藏了出于实用原因而需要使用的线程。MongoDB 的[马达](https://fpy.li/21-23)异步驱动程序有一个与`async/await`兼容的 API，它实际上是一个围绕着与数据库服务器对话的线程核心的外观。答:Jesse Jiryu Davis，Motor 的首席开发者，在[“对‘异步 Python 和数据库’的回应”](https://fpy.li/21-24)中解释了他的推理。剧透:Davis 发现线程池在数据库驱动程序的特定用例中性能更好——尽管有传言说异步方法总是比网络 I/O 的线程更快。

将 explict `Executor`传递给`loop.run_in_executor`的主要原因是，如果要执行的函数是 CPU 密集型的，那么就使用一个`ProcessPoolExecutor`，这样它就可以在不同的 Python 进程中运行，避免争夺 GIL。因为启动成本高，不如在`supervisor`中启动`ProcessPoolExecutor`，传给需要使用的协程。

Caleb Hattingh 是《在 Python (O' Reilly)中使用 Asyncio 的 [*一书的作者，他是这本书的技术评论家之一，建议我添加以下关于执行者和 *asyncio* 的警告。*](https://fpy.li/hattingh)

# 凯莱布关于执行人磨合的警告

使用`run_in_executor`会产生难以调试的问题，因为取消并不像预期的那样工作。使用执行器的协程仅仅给出了取消的借口:底层线程(如果是一个`ThreadPoolExecutor`)没有取消机制。例如，在一个`run_in_executor`调用中创建的一个长寿命线程可能会阻止您的 *asyncio* 程序干净地关闭:`asyncio.run`将在返回之前等待执行程序完全关闭，如果执行程序的作业没有以某种方式自行停止，它将永远等待。我的灰胡子倾向是想把那个功能命名为 `run_in_executor_uncancellable`。

我们现在将从客户端脚本转到使用`asyncio`编写服务器。

# 编写 asyncio 服务器

TCP 服务器的经典例子是回送服务器。我们将构建更有趣的玩具:服务器端 Unicode 字符搜索工具，首先使用 HTTP 和 *FastAPI* ，然后只使用普通 TCP 和`asyncio`。

这些服务器允许用户基于标准名称中的单词从我们在“Unicode 数据库”](ch04.xhtml#unicodedata_sec)中讨论的`unicodedata`模块中查询 Unicode 字符。[图 21-2 显示了与 *web_mojifinder.py* 的会话，这是我们将要构建的第一个服务器。

![Screenshot of Firefox connection to web_mojifinder.py](Images/flpy_2102.png)

###### 图 21-2。显示来自 web_mojifinder.py 服务的“mountain”的搜索结果的浏览器窗口。

这些例子中的 Unicode 搜索逻辑位于 *Fluent Python* 代码库](https://fpy.li/code)中 *charindex.py* 模块的`InvertedIndex`类中。在那个小模块中没有并发的东西，所以我只在下面的可选框中给出一个简要的概述。您可以跳到[“一个 FastAPI Web 服务”中的 HTTP 服务器实现。

## FastAPI Web 服务

我写了下一个例子——*Web _ moji finder . py*——使用 *FastAPI*](https://fpy.li/21-28) :在“ASGI——异步服务器网关接口”中提到的 Python ASGI Web 框架之一。[图 21-2 是前端的截图。这是一个超级简单的 SPA(单页应用程序):在最初的 HTML 下载之后，UI 由与服务器通信的客户端 JavaScript 更新。

FastAPI 旨在为 SPA 和移动应用程序实现后端，主要由返回 JSON 响应的 web API 端点组成，而不是服务器呈现的 HTML。 *FastAPI* 利用装饰器、类型提示和代码自省来消除 web APIs 的大量样板代码，并且还自动发布交互式 open API——也称为Swagger](https://fpy.li/21-29)——我们创建的 API 的文档。[图 21-4 显示了 *web_mojifinder.py* 自动生成的`/docs`页面。

![Screenshot of Firefox showing OpenAPI schema for `/search` endpoint](Images/flpy_2104.png)

###### 图 21-4。为`/search`端点自动生成的 OpenAPI 模式。

示例 21-11 是 *web_mojifinder.py* 的代码，但那只是后端代码。当你点击根 URL `/`时，服务器发送*form.html*文件，该文件有 81 行代码，包括 54 行 JavaScript 来与服务器通信，并用结果填充一个表格。如果你对阅读普通的无框架 JavaScript 感兴趣，请在 [*Fluent Python* 代码库](https://fpy.li/code)中找到*21-async/moji finder/static/form . html*。

要运行 *web_mojifinder.py* ，需要安装两个包及其依赖: *FastAPI* 和 *uvicorn* 。 ^(10](ch21.xhtml#idm46582383270064)) 这是在开发模式下使用*uv icon*运行[示例 21-11 的命令:

```
$ uvicorn web_mojifinder:app --reload
```

这些参数是:

`web_mojifinder:app`

包名、冒号和其中定义的 ASGI 应用程序的名称— `app`是常规名称。

`--reload`

让*uvicon*监控应用程序源文件的变化并自动重新加载它们。仅在开发期间有用。

现在我们来研究一下 *web_mojifinder.py* 的源代码。

##### 示例 21-11： web_mojifinder.py:完整源代码

```
frompathlibimportPathfromunicodedataimportnamefromfastapiimportFastAPIfromfastapi.responsesimportHTMLResponsefrompydanticimportBaseModelfromcharindeximportInvertedIndexSTATIC_PATH=Path(__file__).parent.absolute()/'static'①app=FastAPI(②title='Mojifinder Web',description='Search for Unicode characters by name.',)classCharName(BaseModel):③char:strname:strdefinit(app):④app.state.index=InvertedIndex()app.state.form=(STATIC_PATH/'form.html').read_text()init(app)⑤@app.get('/search',response_model=list[CharName])⑥asyncdefsearch(q:str):⑦chars=sorted(app.state.index.search(q))return({'char':c,'name':name(c)}forcinchars)⑧@app.get('/',response_class=HTMLResponse,include_in_schema=False)defform():⑨returnapp.state.form# no main funcion ⑩
```

① 与本章的主题无关，但值得注意的是:`pathlib`对重载的`/`操作符的优雅使用。 [11]

② 这一行定义了 ASGI 应用。可能就像`app = FastAPI()`一样简单。显示的参数是自动生成的文档的元数据。

③ 带有`char`和`name`字段的 JSON 响应的 *pydantic* 模式。 [12]

④ 构建`index`并加载静态 HTML 表单，将两者都附加到`app.state`供以后使用。

⑤ ASGI 服务器加载该模块时运行`init`。

⑥ `/search`端点的路线；`response_model`使用那个`CharName` *pydantic* 模型来描述响应格式。

⑦ *FastAPI* 假设在函数或协程签名中出现的、不在路由路径中的任何参数都将在 HTTP 查询字符串中传递，例如`/search?q=cat`。由于`q`没有默认值，如果查询字符串中缺少`q`，那么 *FastAPI* 将返回 422(不可处理的实体)状态。

⑧ 返回与`response_model`模式兼容的`dicts`的 iterable 允许 *FastAPI* 根据`@app.get`装饰器中的`response_model`构建 JSON 响应。

⑨ 常规函数(即非异步函数)也可以用来产生响应。

⑩ 这个模块没有主函数。它由 ASGI 服务器加载和驱动，在本例中为*uvicon*。

示例 21-11 没有对`asyncio`的直接调用。 *FastAPI* 构建在 *Starlette* ASGI 工具包上，后者反过来使用`asyncio`。

还要注意的是，`search`的主体没有使用`await`、`async with`或`async for`，因此它可能是一个普通的函数。我将`search`定义为一个协程，只是为了表明 *FastAPI* 知道如何处理它。在真实的应用程序中，大多数端点将查询数据库或访问其他远程服务器，因此*FastAPI*——以及一般的 ASGI 框架——支持能够利用异步库进行网络 I/O 的协同程序是一个关键优势。

###### 小费

我编写的用于加载和服务静态 HTML 表单的`init`和`form`函数是为了使示例简短且易于运行。推荐的最佳实践是在 ASGI 服务器前面有一个代理/负载平衡器来处理所有静态资产，并且在可能的情况下使用 CDN(内容交付网络)。一个这样的代理/负载平衡器是 [*Traefik*](https://fpy.li/21-32) ，一个自称的“边缘路由器”，它“代表你的系统接收请求，并找出哪些组件负责处理它们。” *FastAPI* 有[项目生成](https://fpy.li/21-33)脚本，让你的代码做好准备。

打字爱好者可能注意到了`search`和`form`中没有返回类型提示。相反， *FastAPI* 依赖于路由装饰器中的`response_model=`关键字参数。 *FastAPI* 文档中的[“响应模型”](https://fpy.li/21-34)页面解释道:

> 响应模型在该参数中声明，而不是作为函数返回类型注释，因为路径函数可能实际上不返回该响应模型，而是返回 dict、数据库对象或一些其他模型，然后使用`response_model`来执行字段限制和序列化。

例如，在`search`中，我返回了一个`dict`项的生成器，而不是一个`CharName`对象的列表，但是这对于 *FastAPI* 和 *pydantic* 来说已经足够好了，可以验证我的数据并构建与`response_model=list[CharName]`兼容的适当的 JSON 响应。

我们现在将关注 *tcp_mojifinder.py* 脚本，它正在回答图 21-5 中的查询。

## asyncio TCP 服务器

*tcp _ moji finder . py*程序使用简单的 TCP 与 Telnet 或 Netcat 等客户端进行通信，因此我可以使用`asyncio`编写它，而无需外部依赖——也无需重新发明 HTTP。图 21-5 显示了基于文本的用户界面。

![Screenshot of Telnet connection to tcp_mojifinder.py](Images/flpy_2105.png)

###### 图 21-5。与 tcp_mojifinder.py 服务器的 Telnet 会话:查询“fire”

这个程序比 *web_mojifinder.py* 长一倍，所以我把演示分成三部分:示例 21-12 、示例 21-14 、示例 21-15 。*TCP _ moji finder . py*——包括`import`语句——的顶部在示例 21-14 中，但我将从描述驱动程序的`supervisor`协程和`main`函数开始。

##### 示例 21-12： tcp_mojifinder.py:一个简单的 tcp 服务器；上接示例 21-14

```
asyncdefsupervisor(index:InvertedIndex,host:str,port:int)->None:server=awaitasyncio.start_server(①functools.partial(finder,index),②host,port)③socket_list=cast(tuple[TransportSocket,...],server.sockets)④addr=socket_list[0].getsockname()print(f'Serving on {addr}. Hit CTRL-C to stop.')⑤awaitserver.serve_forever()⑥defmain(host:str='127.0.0.1',port_arg:str='2323'):port=int(port_arg)print('Building index.')index=InvertedIndex()⑦try:asyncio.run(supervisor(index,host,port))⑧exceptKeyboardInterrupt:⑨print('\nServer shut down.')if__name__=='__main__':main(*sys.argv[1:])
```

① 这个`await`快速获得一个`asyncio.Server`的实例，一个 TCP 套接字服务器。默认情况下，`start_server`创建并启动服务器，因此它准备好接收连接。

② `start_server`的第一个参数是`client_connected_cb`，这是一个在新的客户端连接启动时运行的回调。回调可以是一个函数或者一个协程，但是它必须接受两个参数:一个`asyncio.StreamReader`和一个`asyncio.StreamWriter`。然而，我的`finder`协程也需要获得一个`index`，所以我使用了`functools.partial`来绑定那个参数，并获得一个接受读取器和写入器的可调用对象。使用户函数适应回调 API 是`functools.partial`最常见的用例。

③ `host`和`port`是`start_server`的第二个和第三个自变量。参见 [`asyncio`文档](https://fpy.li/21-35)中的完整签名。

④ 这个`cast`是必需的，因为*类型化的*对于`Server`类的`sockets`属性有一个过时的类型提示——截止到 2021 年 5 月。参见*排版* 上的问题#5535。](https://fpy.li/21-36)[13

⑤ 显示服务器第一个套接字的地址和端口。

⑥ 虽然`start_server`已经作为并发任务启动了服务器，但是我需要在`server_forever`方法上`await`，这样我的`supervisor`就在这里挂起了。如果没有这一行，`supervisor`将立即返回，结束从`asyncio.run(supervisor(…))`开始的循环，并退出程序。`Server.serve_forever` 的[文档说:“如果服务器已经在接受连接，就可以调用这个方法。”](https://fpy.li/21-37)

⑦ 构建倒排索引。 [14]

⑧ 启动事件循环运行`supervisor`。

⑨ 当我在运行服务器的终端上用 Ctrl-C 停止服务器时，捕捉`KeyboardInterrupt`以避免令人分心的回溯。

如果研究它在服务器控制台上生成的输出，你会发现更容易理解 *tcp_mojifinder.py* 中的控制流，如示例 21-13 中所列。

##### 示例 21-13：这是在图 21-5 中描述的会话的服务器端

```
$ python3 tcp_mojifinder.py
Building index. ① Serving on ('127.0.0.1', 2323). Hit Ctrl-C to stop. ② From ('127.0.0.1', 58192): 'cat face' ③ To ('127.0.0.1', 58192): 10 results.
 From ('127.0.0.1', 58192): 'fire' ④ To ('127.0.0.1', 58192): 11 results.
 From ('127.0.0.1', 58192): '\x00' ⑤ Close ('127.0.0.1', 58192). ⑥ ^C ⑦ Server shut down. ⑧ $
```

① 由`main`输出。在下一行出现之前，我看到我的机器在建立索引时有 0.6 秒的延迟。

② 由`supervisor`输出。

③ `finder`中`while`循环的第一次迭代。TCP/IP 堆栈将端口 58192 分配给我的 Telnet 客户端。如果您将几个客户端连接到服务器，您将在输出中看到它们的各种端口。

④ `finder`中`while`循环的第二次迭代。

⑤ 我在客户端敲了 Ctrl-C；`finder`中的`while`循环退出。

⑥ `finder`协程显示此消息，然后退出。与此同时，服务器仍在运行，准备为另一个客户机服务。

⑦ 我在服务器端按了 Ctrl-C；`server.serve_forever`取消，结束`supervisor`和事件循环。

⑧ 由`main`输出。

在`main`建立索引并开始事件循环后，`supervisor`快速显示`Serving on…`信息并在`await server.serve_forever()`行暂停。此时，控制流入事件循环并停留在那里，偶尔返回到`finder`协程，每当需要等待网络发送或接收数据时，协程将控制交还给事件循环。

当事件循环存在时，将为连接到服务器的每个客户机启动一个新的`finder`协程实例。这样，这个简单的服务器可以同时处理许多客户机。这一直持续到服务器上出现`KeyboardInterrupt`或者它的进程被操作系统终止。

现在让我们看看 *tcp_mojifinder.py* 的顶部，带有`finder`协程。

##### 示例 21-14： tcp_mojifinder.py:上接示例 21-12

```
importasyncioimportfunctoolsimportsysfromasyncio.trsockimportTransportSocketfromtypingimportcastfromcharindeximportInvertedIndex,format_results①CRLF=b'\r\n'PROMPT=b'?> 'asyncdeffinder(index:InvertedIndex,②reader:asyncio.StreamReader,writer:asyncio.StreamWriter)->None:client=writer.get_extra_info('peername')③whileTrue:④writer.write(PROMPT)# can't await! ⑤awaitwriter.drain()# must await! ⑥data=awaitreader.readline()⑦ifnotdata:⑧breaktry:query=data.decode().strip()⑨exceptUnicodeDecodeError:⑩query='\x00'print(f' From {client}: {query!r}')⑪ifquery:iford(query[:1])<32:⑫breakresults=awaitsearch(query,index,writer)⑬print(f' To {client}: {results} results.')⑭writer.close()⑮awaitwriter.wait_closed()⑯print(f'Close {client}.')⑰
```

① `format_results`有助于在基于文本的 UI 中显示`InvertedIndex.search`的结果，比如命令行或 Telnet 会话。

② 为了将`finder`传递给`asyncio.start_server`，我用`functools.partial`包装了它，因为服务器期望一个只接受`reader`和`writer`参数的协程或函数。

③ 获取套接字连接的远程客户端地址。

④ 这个循环处理一个对话，这个对话一直持续到从客户端收到一个控制字符。

⑤ `StreamWriter.write`方法不是一个协程，只是一个普通的函数；该行发送`?>`提示。

⑥ `StreamWriter.drain`刷新`writer`缓冲区；它是一个协程，所以必须用`await`驱动。

⑦ `StreamWriter.readline`是返回`bytes`的协程。

⑧ 如果没有收到字节，客户端关闭连接，所以退出循环。

⑨ 使用默认的 UTF-8 编码对`bytes`至`str`进行解码。

⑩ 当用户点击 Ctrl-C，Telnet 客户端发送控制字节时，可能会发生`UnicodeDecodeError`；如果发生这种情况，为了简单起见，用空字符替换查询。

⑪ 将查询记录到服务器控制台。

⑫ 如果收到控制字符或空字符，则退出循环。

⑬ 做实际的`search`；接下来是代码。

⑭ 将响应记录到服务器控制台。

⑮ 关闭`StreamWriter`。

⑯ 等待`StreamWriter`关闭。这是在 [`.close()`方法文档](https://fpy.li/21-38)中推荐的。

⑰ 将此客户机会话的结束记录到服务器控制台。

该示例的最后一部分是`search`协程，如示例 21-15 所示。

##### 示例 21-15： tcp_mojifinder.py: `search`协程

```
asyncdefsearch(query:str,①index:InvertedIndex,writer:asyncio.StreamWriter)->int:chars=index.search(query)②lines=(line.encode()+CRLFforline③informat_results(chars))writer.writelines(lines)④awaitwriter.drain()⑤status_line=f'{"─" * 66} {len(chars)} found'⑥writer.write(status_line.encode()+CRLF)awaitwriter.drain()returnlen(chars)
```

① `search`必须是协程，因为它写入`StreamWriter`并且必须使用其`.drain()`协程方法。

② 查询倒排索引。

③ 这个生成器表达式将产生以 UTF-8 编码的字节串，带有 Unicode 码点、实际字符、其名称和一个`CRLF`序列——例如 `b'U+0039\t9\tDIGIT NINE\r\n'` )。

④ 发送`lines`。令人惊讶的是，`writer.writelines`并不是协程。

⑤ 但是`writer.drain()`是一个协程。别忘了`await`！

⑥ 建立一个状态行，然后发送。

注意 *tcp_mojifinder.py* 中的所有网络 I/O 都在`bytes`中；我们需要对从网络上接收到的`bytes`进行解码，并在发送出去之前对字符串进行编码。在 Python 3 中，默认编码是 UTF-8，在这个例子中，我在所有的`encode`和`decode`调用中都隐式地使用了这种编码。

###### 警告

注意，一些 I/O 方法是协程，必须用`await`驱动，而其他的是简单的函数。例如，`StreamWriter.write`是一个普通函数，因为它写入缓冲区。另一方面，`StreamWriter.drain`——刷新缓冲区并执行网络 I/O——是一个协程，因为是`StreamReader.readline`——但不是`StreamWriter.writelines`！当我写这本书的第一版时，`asyncio` API 文档被[改进，明确地将协程标记为这样的](https://fpy.li/21-39)。

*tcp_mojifinder.py* 代码利用了高级`asyncio` [Streams API](https://fpy.li/21-40) ，它提供了一个随时可用的服务器，因此您只需要实现一个处理函数，它可以是一个普通的回调函数或一个协程程序。还有一个较低级别的[传输和协议 API](https://fpy.li/21-41) ，灵感来自于 *Twisted* 框架中的传输和协议抽象。有关更多信息，请参考`asyncio`文档，包括用该低级 API 实现的 [TCP 和 UDP echo 服务器和客户端](https://fpy.li/21-42)。

我们的下一个主题是`async for`和让它工作的对象。T34

# 异步迭代和异步可迭代

我们 在“异步上下文管理器”中看到了`async with`如何处理实现了返回可访问对象的`__aenter__`和`__aexit__`方法的对象——通常是以协程对象的形式。

类似地，`async for`与*异步可迭代对象*一起工作:实现`__aiter__`的对象。然而，`__aiter__`必须是常规方法——而不是协程方法——并且它必须返回一个*异步迭代器*。

异步迭代器提供了一个`__anext__`协程方法，该方法返回一个可变量——通常是一个协程对象。他们还需要实现`__aiter__`，通常会返回`self`。这反映了我们在“不要让可迭代对象成为自身的迭代器”中讨论的可迭代对象和迭代器的重要区别。

*aiopg* 异步 PostgreSQL 驱动程序[文档](https://fpy.li/21-43)中有一个示例说明了如何使用`async for`迭代数据库游标的行:

```
async def go():
    pool = await aiopg.create_pool(dsn)
    async with pool.acquire() as conn:
        async with conn.cursor() as cur:
            await cur.execute("SELECT 1")
            ret = []
            async for row in cur:
                ret.append(row)
            assert ret == [(1,)]
```

在这个例子中，查询将返回一行，但是在现实场景中，您可能有数千行来响应一个`SELECT`查询。对于大型响应，游标不会在一个批处理中加载所有行。因此，当光标可能正在等待其他行时，`async for row in cur:`不阻塞事件循环是很重要的。通过将游标实现为异步迭代器， *aiopg* 可以在每次`__anext__`调用时屈服于事件循环，并在稍后当更多的行从 PostgreSQL 到达时恢复。

## 异步发电机功能

你可以用`__anext__`和`__aiter__`写一个类来实现异步迭代器，但是有一个更简单的方法:写一个用`async def`声明的函数，并在它的体中使用`yield`。这类似于生成器函数如何简化经典迭代器模式。

让我们研究一个使用`async for`并实现异步生成器的简单例子。在示例 21-1 中我们看到了 *blogdom.py* ，一个探查域名的脚本。现在假设我们发现了我们在那里定义的`probe`协程的其他用途，并决定将它放入一个新的模块—*domain lib . py*—以及一个新的`multi_probe`异步生成器，该生成器获取域名列表并在被探测时产生结果。

我们很快就会看到 *domainlib.py* 的实现，但首先让我们看看它是如何与 Python 的新异步控制台一起使用的。

### 试用 Python 的异步控制台

从 Python 3.8](https://fpy.li/21-44) 开始，您可以使用`-m asyncio`命令行选项来运行解释器，以获得“异步 REPL”:一个导入`asyncio`的 Python 控制台，提供一个运行事件循环，并在顶级提示符处接受`await`、`async for`和`async with`——否则在本机协同程序之外使用时会出现语法错误。 ^([15)

要尝试使用 *domainlib.py* ，请转到 [*Fluent Python* 代码库](https://fpy.li/code)的本地副本中的*21-async/domains/async io/*目录。然后运行:

```
$ python -m asyncio
```

您将看到控制台启动，如下所示:

```
asyncio REPL 3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52)
[Clang 6.0 (clang-600.0.57)] on darwin
Use "await" directly instead of "asyncio.run()".
Type "help", "copyright", "credits" or "license" for more information.
>>> import asyncio
>>>
```

请注意标题是如何说您可以使用`await`而不是`asyncio.run()`——来驱动协程和其他 awaitables。另外:我没有输入`import asyncio`。`asyncio`模块被自动导入，这一行向用户清楚地表明了这一事实。

现在我们导入 *domainlib.py* ，玩玩它的两个协程:`probe`和`multi_probe` ( 示例 21-16 )。

##### 示例 21-16：运行`python3 -m asyncio`后用 *domainlib.py* 做实验

```
>>> awaitasyncio.sleep(3,'Rise and shine!')①'Rise and shine!' >>> fromdomainlibimport*>>> awaitprobe('python.org')②Result(domain='python.org', found=True) ③>>> names='python.org rust-lang.org golang.org no-lang.invalid'.split()④>>> asyncforresultinmulti_probe(names):⑤... print(*result,sep='\t')...golang.org      True ⑥no-lang.invalid False python.org      True rust-lang.org   True >>>
```

① 尝试一个简单的`await`来看看异步控制台的运行。提示:`asyncio.sleep()`接受一个可选的第二个参数，当您`await`调用它时会返回这个参数。

② 驱动`probe`协程。

③ `probe`的`domainlib`版本返回一个名为元组的`Result`。

④ 制作一个域名列表。`.invalid`顶级域名保留用于测试。对此类域的 DNS 查询总是从 DNS 服务器获得 NXDOMAIN 响应，这意味着“该域不存在。” [16]

⑤ 用`async for`迭代`multi_probe`异步发电机以显示结果。

⑥ 请注意，结果不是按照域被给予`multiprobe`的顺序。它们在每个 DNS 响应返回时出现。

示例 21-16 说明`multi_probe`是异步发电机，因为它与`async for`兼容。现在让我们再做几个实验，从那个例子继续例子 21-17 。

##### 示例 21-17：更多实验，上接示例 21-16

```
>>> probe('python.org')①<coroutine object probe at 0x10e313740> >>> multi_probe(names)②<async_generator object multi_probe at 0x10e246b80> >>> forrinmulti_probe(names):③... print(r)...Traceback (most recent call last):
...TypeError: 'async_generator' object is not iterable
```

① 调用本机协程会给你一个协程对象。

② 调用异步生成器会给你一个`async_generator`对象。

③ 我们不能对异步发电机使用常规的`for`循环，因为它们实现了`__aiter__`而不是`__iter__`。

异步生成器由`async for`驱动，它可以是一个块语句(如示例 21-16 所示)，它也出现在异步理解中，我们很快会谈到。

### 实现异步生成器

现在让我们研究一下 *domainlib.py* 的代码，使用`multi_probe`异步生成器(示例 21-18 )。

##### 示例 21-18： domainlib.py:用于探测域的函数

```
importasyncioimportsocketfromcollections.abcimportIterable,AsyncIteratorfromtypingimportNamedTuple,OptionalclassResult(NamedTuple):①domain:strfound:boolOptionalLoop=Optional[asyncio.AbstractEventLoop]②asyncdefprobe(domain:str,loop:OptionalLoop=None)->Result:③ifloopisNone:loop=asyncio.get_running_loop()try:awaitloop.getaddrinfo(domain,None)exceptsocket.gaierror:returnResult(domain,False)returnResult(domain,True)asyncdefmulti_probe(domains:Iterable[str])->AsyncIterator[Result]:④loop=asyncio.get_running_loop()coros=[probe(domain,loop)fordomainindomains]⑤forcoroinasyncio.as_completed(coros):⑥result=awaitcoro⑦yieldresult⑧
```

① `NamedTuple`使`probe`的结果更容易阅读和调试。

② 这个类型别名是为了避免下一行对于图书清单来说太长。

③ `probe`现在得到一个可选的`loop`参数，以避免当这个协程由`multi_probe`驱动时重复调用`get_running_loop`。

④ 一个异步生成器函数产生一个异步生成器对象，可以注释为`AsyncIterator[SomeType]`。

⑤ 构建`probe`协程对象的列表，每个对象都有不同的`domain`。

⑥ 这不是`async for`因为`asyncio.as_completed`是经典发电机。

⑦ 在协程对象上等待以检索结果。

⑧ 产量`result`。这条线使`multi_probe`成为异步发电机。

###### 注意

示例 21-18 中的`for`循环可以更简洁:

```
    for coro in asyncio.as_completed(coros):
        yield await coro
```

Python 将其解析为`yield (await coro)`，因此它可以工作。

我认为在本书的第一个异步生成器示例中使用该快捷方式可能会令人困惑，所以我将它分成两行。

给定 *domainlib.py* ，我们可以在 *domaincheck.py* 中演示`multi_probe`异步生成器的使用:一个接受域后缀并搜索由短 Python 关键字组成的域的脚本。

下面是 *domaincheck.py* 的示例输出:

```
$ ./domaincheck.py net
FOUND           NOT FOUND
=====           =========
in.net
del.net
true.net
for.net
is.net
                none.net
try.net
                from.net
and.net
or.net
else.net
with.net
if.net
as.net
                elif.net
                pass.net
                not.net
                def.net
```

由于有了 *domainlib* ，所以 *domaincheck.py* 的代码很简单，如示例 21-19 所示。

##### 示例 21-19： domaincheck.py:使用 domainlib 探测域的实用程序

```
#!/usr/bin/env python3importasyncioimportsysfromkeywordimportkwlistfromdomainlibimportmulti_probeasyncdefmain(tld:str)->None:tld=tld.strip('.')names=(kwforkwinkwlistiflen(kw)<=4)①domains=(f'{name}.{tld}'.lower()fornameinnames)②print('FOUND\t\tNOT FOUND')③print('=====\t\t=========')asyncfordomain,foundinmulti_probe(domains):④indent=''iffoundelse'\t\t'⑤print(f'{indent}{domain}')if__name__=='__main__':iflen(sys.argv)==2:asyncio.run(main(sys.argv[1]))⑥else:print('Please provide a TLD.',f'Example: {sys.argv[0]} COM.BR')
```

① 生成长度不超过`4`的关键词。

② 生成带有给定后缀 TLD 的域名。

③ 格式化表格输出的标题。

④ 异步迭代`multi_probe(domains)`。

⑤ 将`indent`设置为零或两个标签，将结果放入适当的列。

⑥ 使用给定的命令行参数运行`main`协程。

生成器还有一个与迭代无关的额外用途:它们可以成为上下文管理器。这也适用于异步发电机。

### 作为上下文管理器的异步生成器

编写我们自己的异步上下文管理器并不是一项频繁的编程任务，但是如果您需要编写一个，可以考虑使用 Python 3.7 中添加到`contextlib`模块的 `@asynccontextmanager`](https://fpy.li/21-46) 装饰器。这与我们在[“使用@ context manager”中学习的`@contextmanager`装饰器非常相似。

一个将`@asynccontextmanager`和`loop.run_in_executor`结合的有趣例子出现在 Caleb Hattingh 的书 *中在 Python*](https://fpy.li/hattingh) 中使用 Asyncio。[示例 21-20 是 Caleb 的代码——仅做了一处更改并添加了标注。

##### 示例 21-20：使用`@asynccontextmanager`和`loop.run_in_executor`的示例

```
fromcontextlibimportasynccontextmanager@asynccontextmanagerasyncdefweb_page(url):①loop=asyncio.get_running_loop()②data=awaitloop.run_in_executor(③None,download_webpage,url)yielddata④awaitloop.run_in_executor(None,update_stats,url)⑤asyncwithweb_page('google.com')asdata:⑥process(data)
```

① 修饰函数必须是异步生成器。

② Caleb 代码的小更新:使用轻量级的`get_running_loop`而不是`get_event_loop`。

③ 假设`download_webpage`是一个使用*请求*库的阻塞函数；我们在一个单独的线程中运行它，以避免阻塞事件循环。

④ 这个`yield`表达式之前的所有行都将成为装饰器构建的异步上下文管理器的`__aenter__`协程方法。`data`的值将被绑定到下面`async with`语句中`as`子句后的`data`变量。

⑤ 在`yield`之后的行将成为`__aexit__`协程方法。这里，另一个阻塞调用被委托给线程执行器。

⑥ 将`web_page`与`async with`一起使用。

这非常类似于顺序的`@contextmanager`装饰器。请参见“使用@ context manager”了解更多详情，包括`yield`行的错误处理。关于`@asynccontextmanager`的另一个例子，参见 [`contextlib`文档](https://fpy.li/21-46)。

现在，让我们通过将异步生成器函数与本机协程进行对比来总结我们对异步生成器函数的介绍。

### 异步生成器与本机协程

下面是本机协程和异步生成器函数之间的一些关键相似之处和不同之处:

*   两者都用`async def`声明。

*   异步生成器的主体中总是有一个`yield`表达式——这就是它成为生成器的原因。本机协程从不包含`yield`。

*   一个本地协程可以`return`除了`None`之外的一些值。异步生成器只能使用空的`return`语句。

*   原生协程是可调整的:它们可以由`await`表达式驱动，或者传递给采用可调整参数的众多`asyncio`函数之一，比如`create_task`。异步发电机不适用。它们是异步可迭代的，由`async for`或异步理解驱动。

是时候讨论异步理解了。

## 异步理解和异步生成器表达式

[PEP 530—异步理解](https://fpy.li/pep530)介绍了 在理解和生成器表达式的语法中`async for`和`await`的使用，从 Python 3.6 开始。

PEP 530 定义的唯一可以出现在`async def`主体外部的结构是异步生成器表达式。

### 定义和使用异步生成器表达式

给定来自示例 21-18 的`multi_probe`异步生成器，我们可以编写另一个异步生成器，只返回找到的域名。下面是如何使用异步控制台启动`-m asyncio`:

```
>>> fromdomainlibimportmulti_probe>>> names='python.org rust-lang.org golang.org no-lang.invalid'.split()>>> gen_found=(nameasyncforname,foundinmulti_probe(names)iffound)①>>> gen_found<async_generator object <genexpr> at 0x10a8f9700> ②>>> asyncfornameingen_found:③... print(name)...golang.org python.org rust-lang.org
```

① `async for`的使用使其成为一个异步生成器表达式。它可以在 Python 模块中的任何地方定义。

② 异步生成器表达式构建了一个`async_generator`对象——与类似`multi_probe`的异步生成器函数返回的对象类型完全相同。

③ 异步生成器对象由`async for`语句驱动，该语句只能出现在`async def`主体内部或我在本例中使用的神奇异步控制台中。

总结一下:异步生成器表达式可以在程序中的任何地方定义，但是它只能在本机协程或异步生成器函数中使用。

PEP 530 引入的其余构造只能在本机协程或异步生成器函数中定义和使用。

### 异步理解

《PEP 530》的作者尤里·塞利万诺夫(Yury Selivanov)用三个简短的代码片段证明了异步理解的必要性。

我们都同意我们应该能够重写这段代码:

```
result = []
async for i in aiter():
    if i % 2:
        result.append(i)
```

像这样:

```
result = [i async for i in aiter() if i % 2]
```

此外，给定一个本机协程`fun`，我们应该能够这样写:

```
result = [await fun() for fun in funcs]
```

###### 小费

在列表理解中使用`await`类似于使用`asyncio.gather`。但是`gather`给了你对异常处理更多的控制权，这要感谢它可选的`return_exceptions`参数。Caleb Hattingh 建议始终设置`return_exceptions=True`(默认为`False`)。更多信息请参见 [`asyncio.gather`文档](https://fpy.li/21-48)。

回到神奇的异步控制台:

```
>>> names = 'python.org rust-lang.org golang.org no-lang.invalid'.split()
>>> names = sorted(names)
>>> coros = [probe(name) for name in names]
>>> await asyncio.gather(*coros)
[Result(domain='golang.org', found=True),
Result(domain='no-lang.invalid', found=False),
Result(domain='python.org', found=True),
Result(domain='rust-lang.org', found=True)]
>>> [await probe(name) for name in names]
[Result(domain='golang.org', found=True),
Result(domain='no-lang.invalid', found=False),
Result(domain='python.org', found=True),
Result(domain='rust-lang.org', found=True)]
>>>
```

注意，在这两种情况下，我对姓名列表进行了排序，以显示结果按照提交的顺序出现。

PEP 530 允许在列表理解以及`dict`和`set`理解中使用`async for`和`await`。例如，下面是将`multi_probe`的结果存储在异步控制台中的`dict`理解:

```
>>> {name: found async for name, found in multi_probe(names)}
{'golang.org': True, 'python.org': True, 'no-lang.invalid': False,
'rust-lang.org': True}
```

我们可以在`for`或`async for`子句前的表达式中使用`await`关键字，也可以在`if`子句后的表达式中使用。下面是异步控制台中的一个集合理解，仅收集找到的域:

```
>>> {name for name in names if (await probe(name)).found}
{'rust-lang.org', 'python.org', 'golang.org'}
```

由于`__getattr__`操作符`.`(点)的优先级更高，我不得不在`await`表达式两边加上额外的括号。

同样，所有这些理解只能出现在一个`async def`体中或被施了魔法的异步控制台中。

现在让我们来谈谈`async`语句、`async`表达式以及它们所创建的对象的一个非常重要的特性。这些结构经常与 asyncio 一起使用，但是它们实际上是独立于库的。

# 异步超越异步:古董

Python 的`async/await`语言 构造不依赖于任何特定的事件循环或库。得益于特殊方法提供的可扩展 API，任何有足够动力的人都可以编写自己的异步运行时环境和框架来驱动本地协程、异步生成器等。

大卫·比兹利在他的 [*古玩*](https://fpy.li/21-49) 项目中就是这么做的。他对重新思考如何在一个从头构建的框架中使用这些新的语言特性很感兴趣。回想一下`asyncio`是在 Python 3.4 中发布的，它使用了`yield from`而不是`await`，所以它的 API 不能利用异步上下文管理器、异步迭代器以及`async/await`关键字使之成为可能的一切。因此，与`asyncio`相比， *Curio* 拥有更干净的 API 和更简单的实现。

示例 21-21 显示了 *blogdom.py* 脚本(示例 21-1 )被改写为使用*古董*。

##### 示例 21-21： blogdom.py: 示例 21-1 ，现在使用*古玩*

```
#!/usr/bin/env python3fromcurioimportrun,TaskGroupimportcurio.socketassocketfromkeywordimportkwlistMAX_KEYWORD_LEN=4asyncdefprobe(domain:str)->tuple[str,bool]:①try:awaitsocket.getaddrinfo(domain,None)②exceptsocket.gaierror:return(domain,False)return(domain,True)asyncdefmain()->None:names=(kwforkwinkwlistiflen(kw)<=MAX_KEYWORD_LEN)domains=(f'{name}.dev'.lower()fornameinnames)asyncwithTaskGroup()asgroup:③fordomainindomains:awaitgroup.spawn(probe,domain)④asyncfortaskingroup:⑤domain,found=task.resultmark='+'iffoundelse''print(f'{mark}{domain}')if__name__=='__main__':run(main())⑥
```

① `probe`不需要得到事件循环，因为…

② … `getaddrinfo`是`curio.socket`的顶层函数，而不是`loop`对象的方法——就像在`asyncio`中一样。

③ 一个`TaskGroup`是 *Curio* 中的核心概念，用来监视和控制几个协程，并确保它们都被执行和清理。

④ `TaskGroup.spawn`是如何启动一个协同程序，由一个特定的`TaskGroup`实例管理。协程由一个`Task`包装。

⑤ 用`async for`在`TaskGroup`上迭代产生`Task`个实例，因为每个实例都是完成的。这对应于示例 21-1 中使用 `for … as_completed(…):`的线条。

⑥ Curio 开创了这种在 Python 中启动异步程序的明智方式。

为了扩展最后一点:如果你查看第一版 *Fluent Python* 的`asyncio`代码示例，你会看到这样的代码行，一遍又一遍地重复:

```
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
    loop.close()
```

一个 *Curio* `TaskGroup`是一个异步上下文管理器，它取代了`asyncio`中的几个特定 API 和编码模式。我们刚刚看到了如何迭代一个`TaskGroup`使得`asyncio.as_completed(…)`函数变得不必要。另一个例子:这个来自[“任务组”文档](https://fpy.li/21-50)的片段收集了组中所有任务的结果，而不是一个特殊的`gather`函数:

```
async with TaskGroup(wait=all) as g:
    await g.spawn(coro1)
    await g.spawn(coro2)
    await g.spawn(coro3)
print('Results:', g.results)
```

任务 组支持 [*结构化并发*](https://fpy.li/21-51) :一种并发编程的形式，将一组异步任务的所有活动约束到一个入口和出口点。这类似于结构化编程，它避开了`GOTO`命令，引入了块语句来限制循环和子例程的入口和出口点。当用作异步上下文管理器时，`TaskGroup`确保在退出封闭块时，内部产生的所有任务都被完成或取消，并引发任何异常。

###### 注意

在即将到来的 Python 版本中,`asyncio`可能会采用结构化并发。在[PEP 654——例外组和例外*](https://fpy.li/pep654) 中出现了一个强烈的指示，这是为 Python 3.11 批准的[。](https://fpy.li/21-52)[“动机”部分](https://fpy.li/21-53)提到了 *Trio 的*“托儿所”，他们对任务组的称呼:“受 Trio 托儿所的启发，在 *asyncio* 中实现一个更好的任务生成 API，是这个 PEP 的主要动机。”

*Curio* 的另一个重要特性是更好地支持在同一个代码库中使用协程和线程进行编程——这是大多数重要的异步程序所必需的。用`await spawn_thread(func, …)`启动一个线程会返回一个带有类似`Task`接口的`AsyncThread`对象。线程可以调用协程，这要感谢一个特殊的 [`AWAIT(coro)`](https://fpy.li/21-54) 函数——全大写命名，因为`await`现在是一个关键字。

*Curio* 还提供了一个`UniversalQueue`，可以用来协调线程、 *Curio* 协程和`asyncio`协程之间的工作。没错， *Curio* 具有允许它在一个线程中与另一个线程中的`asyncio`一起运行的特性，在同一进程中，通过`UniversalQueue`和`UniversalEvent`进行通信。这些“通用”类的 API 在协程内部和外部是相同的，但是在协程中，您需要给调用加上前缀`await`。

当我在 2021 年 10 月写这篇文章时， *HTTPX* 是第一个与*Curio*兼容的 HTTP 客户端库[，但是我还不知道有任何异步数据库库支持它。在 *Curio* 资源库中，有一组令人印象深刻的](https://fpy.li/21-55)[网络编程示例](https://fpy.li/21-56)，包括一个使用 *WebSocket* 的示例，以及另一个实现[RFC 8305——快乐眼球](https://fpy.li/21-57)并发算法的示例，用于连接到 IPv6 端点，并在需要时快速回退到 IPv4。

古董的设计很有影响力。纳撒尼尔·j·史密斯(Nathaniel J. Smith)开创的 [*三重奏*](https://fpy.li/21-58) 框架深受*古玩*的启发。 *Curio* 可能也促使 Python 贡献者提高了`asyncio` API 的可用性。例如，在其最早的版本中，`asyncio`用户经常不得不获取并传递一个`loop`对象，因为一些基本函数要么是`loop`方法，要么需要一个`loop`参数。在 Python 的最新版本中，不需要经常直接访问循环，事实上，几个接受可选的`loop`的函数现在反对这种说法。

异步类型的类型注释是我们的下一个主题。

# 类型提示异步对象

本机协程的 返回类型描述了当您在那个协程上`await`时得到的东西，它是出现在本机协程函数体的`return`语句中的对象类型。 [18]

本章提供了许多带注释的本机协程的例子，包括来自的`probe`例子 21-21 :

```
async def probe(domain: str) -> tuple[str, bool]:
    try:
        await socket.getaddrinfo(domain, None)
    except socket.gaierror:
        return (domain, False)
    return (domain, True)
```

如果您需要注释采用协程对象的参数，则泛型类型为:

```
class typing.Coroutine(Awaitable[V_co], Generic[T_co, T_contra, V_co]):
    ...
```

Python 3.5 和 3.6 中引入了该类型和以下类型来注释异步对象:

```
class typing.AsyncContextManager(Generic[T_co]):
    ...
class typing.AsyncIterable(Generic[T_co]):
    ...
class typing.AsyncIterator(AsyncIterable[T_co]):
    ...
class typing.AsyncGenerator(AsyncIterator[T_co], Generic[T_co, T_contra]):
    ...
class typing.Awaitable(Generic[T_co]):
    ...
```

对于 Python ≥ 3.9，使用这些的`collections.abc`等价物。

我想强调这些泛型的三个方面。

首先:它们在第一个类型参数上都是协变的，第一个类型参数是从这些对象生成的项的类型。回想一下“经验方差法则”的规则 1:

> 如果形式类型参数为来自对象的数据定义了一种类型，那么它可以是协变的。

第二:`AsyncGenerator`和`Coroutine`是倒数第二个参数的逆变。这就是低级`.send()`方法的参数类型，事件循环调用该方法来驱动异步生成器和协程。因此，它是一种“输入”类型。因此，根据方差经验法则#2，它可以是逆变的:

> 如果一个形式类型参数为数据定义了一个类型，而这个数据在最初构造之后进入对象，那么它可能是逆变的。

第三:`AsyncGenerator`没有返回类型，与`typing.Generator`相反，我们在“经典协程的泛型类型提示”中看到过。通过提高`StopIteration(value)`返回值是使生成器能够作为协程运行并支持`yield from`的一个技巧，正如我们在“经典协程”中看到的。异步对象之间没有这种重叠:`AsyncGenerator`对象不返回值，并且完全独立于本机协程对象，后者用`typing.Coroutine`进行注释。

最后，我们简单讨论一下异步编程的优势和挑战。

# 异步的工作原理和不工作原理

本章结尾部分讨论了异步编程的高级思想，而不管您使用的是什么语言或库。

让我们从解释异步编程吸引人的首要原因开始，然后是一个流行的神话，以及如何处理它。

## 绕着阻止电话跑圈

Node.js 的发明者 Ryan Dahl 介绍了他的项目理念，他说“我们做 I/O 是完全错误的。”他将*阻塞函数*定义为处理文件或网络 I/O 的函数，并认为我们不能像对待非阻塞函数一样对待它们。为了解释原因，他给出了表 21-1 中第二列的数字。

Table 21-1\. Modern computer latency for reading data from different devices; third column shows proportional times in a scale easier to understand for us slow humans

| 设备 | CPU 周期 | “人”的比例尺度 |
| --- | --- | --- |
| L1 高速缓存 | 3 | 3 秒钟 |
| L2 高速缓存 | 14 | 14 秒 |
| 随机存取存储 | 250 | 250 秒 |
| 唱片 | 41,000,000 | 1.3 年 |
| 网络 | 240,000,000 | 7.6 年 |

为了理解表 21-1 ，请记住，具有 GHz 时钟的现代 CPU 每秒运行数十亿个周期。假设一个 CPU 每秒运行 10 亿个周期。该 CPU 可以在 1 秒钟内进行超过 3.33 亿次 L1 缓存读取，即 4(4！)网络同时读取。表 21-1 的第三列通过将第二列乘以一个常数因子来显示这些数字。因此，在另一个世界中，如果从 L1 缓存读取一次需要 3 秒，那么网络读取将需要 7.6 年！

表 21-1 解释了为什么一个训练有素的异步编程方法可以带来高性能的服务器。挑战在于实现这一原则。第一步是认识到“I/O 绑定系统”是一个幻想。

## I/O 绑定系统的神话

一个经常重复的迷因是异步编程对“I/O 受限系统”有好处我艰难地认识到没有“I/O 绑定的系统”你可能有 I/O 绑定的*函数*。也许您系统中的绝大多数函数都是 I/O 受限的；也就是说，他们等待 I/O 的时间比处理数据的时间还要长。在等待时，它们将控制权交给事件循环，后者可以驱动其他一些未完成的任务。但是不可避免的是，任何重要的系统都会有一些部分受到 CPU 的限制。即使是微不足道的系统也显示出，在压力下。在“soap box”，中，我讲述了两个异步程序的故事，这两个程序与 CPU 绑定的函数进行斗争，减慢了事件循环，严重影响了性能。

鉴于任何重要的系统都会有 CPU 限制的函数，处理它们是异步编程成功的关键。

## 避免受 CPU 限制的陷阱

如果您正在大规模使用 Python，那么您应该有一些专门设计的自动化测试，以便在性能退化出现时立即检测出来。这对于异步代码至关重要，但由于 GIL 的原因，它也与线程化 Python 代码相关。如果你等到减速开始困扰开发团队，那就太晚了。修复可能需要一些重大改造。

当您发现占用 CPU 的瓶颈时，以下是一些选项:

*   将任务委托给 Python 进程池。

*   将任务委托给外部任务队列。

*   用 Cython、C、Rust 或其他某种语言重写相关代码，编译成机器码并与 Python/C API 接口，最好发布 GIL。

*   确定您能够承受性能损失，并且什么也不做—但是记录下这个决定，以便以后更容易恢复。

外部任务队列应该在项目开始时尽快选择和集成，以便团队中没有人会在需要时犹豫使用它。

最后一个选项——什么都不做——属于技术债务的范畴。

并发编程是一个迷人的话题，我想写更多关于它的内容。但这不是本书的主要重点，这已经是最长的章节之一了，我们就此打住吧。

# 章节摘要

> 异步编程的常规方法的问题在于它们是要么全有要么全无的命题。你重写所有的代码，这样就不会阻塞，否则你只是在浪费时间。
> 
> 阿尔瓦罗·维德拉和杰森·j·w·威廉姆斯， *RabbitMQ 在行动*

我选择这一章的题词有两个原因。在高层次上，它提醒我们通过将缓慢的任务委派给不同的处理单元来避免阻塞事件循环，从简单的线程一直到分布式任务队列。在更低的层面上，这也是一个警告:一旦你写了你的第一个`async def`，你的程序必然会有越来越多的`async def`、`await`、`async with`、`async for`。使用非异步库突然变成了一个挑战。

在第 19 章的中简单的*微调器*示例之后，这里我们的主要焦点是使用本机协程的异步编程，从 *blogdom.py* DNS 探测示例开始，接着是 *awaitables* 的概念。在读取 *flags_asyncio.py* 的源代码时，我们发现了第一个*异步上下文管理器*的例子。

标志下载程序的更高级版本引入了两个强大的功能:`asyncio.as_completed`生成器和`loop.run_in_executor`协程。我们还看到了信号量的概念和应用，以限制并发下载的数量——正如行为良好的 HTTP 客户端所期望的那样。

服务器端异步编程通过 *mojifinder* 示例呈现:一个 *FastAPI* web 服务和*tcp _ moji finder . py*——后者仅使用`asyncio`和 TCP 协议。

异步迭代和异步可迭代是下一个主要话题，有关于`async for`、Python 的异步控制台、异步生成器、异步生成器表达式和异步理解的章节。

本章的最后一个例子是用 *Curio* 框架重写的 *blogdom.py* ，以展示 Python 的异步特性是如何不依赖于`asyncio`包的。 *Curio* 还展示了*结构化并发*的概念，这可能会对整个行业产生影响，使并发代码更加清晰。

最后，在“Async 如何工作以及如何不工作”下的部分讨论了异步编程的主要吸引力，对“I/O 绑定系统”的误解，以及处理程序中不可避免的 CPU 绑定部分。

# 进一步阅读

David Beazley 的 PyOhio 2016 主题演讲[“异步中的恐惧和等待”](https://fpy.li/21-61)是一个精彩的现场编码介绍，介绍了 Yury Selivanov 对 Python 3.5 中`async/await`关键字的贡献使语言功能的潜力成为可能。Beazley 一度抱怨说`await`不能用于列表理解，但是 Selivanov 在 PEP 530[中解决了这个问题——异步理解](https://fpy.li/pep530)，同年晚些时候在 Python 3.6 中实现。除此之外，Beazley 的主题演讲中的其他内容都是永恒的，因为他演示了我们在本章中看到的异步对象是如何工作的，没有任何框架的帮助——只有一个简单的`run`函数使用`.send(None)`来驱动协程。只是在最后，Beazley 展示了 [*Curio*](https://fpy.li/21-62) ，这是他当年开始的一项实验，目的是看看在没有回调或未来基础的情况下，只有协程，异步编程能走多远。事实证明，你可以走得很远——正如纳撒尼尔·j·史密斯的*古玩*的演变以及后来创作的 [*三重奏*](https://fpy.li/21-58) 所证明的那样。Curio 的文档有[链接](https://fpy.li/21-64)到 Beazley 关于这个主题的更多演讲。

除了开始*三重奏*之外，Nathaniel J. Smith 写了两篇深度博客文章，我强烈推荐:[“关于后异步/等待世界中异步 API 设计的一些想法”](https://fpy.li/21-65)，对比了 *Curio* 和 *asyncio* 的设计，以及[关于结构化并发的“关于结构化并发的说明，或:Go 语句被认为是有害的”](https://fpy.li/21-66)，关于结构化并发。对于这个问题，史密斯也给出了一个很长很翔实的回答:[“asyncio 和 trio 的核心区别是什么？”](https://fpy.li/21-67)在 StackOverflow 上。

为了了解更多关于 *asyncio* 包的信息，我在本章开始时提到了我所知道的最好的书面资源:Yury Selivanov 在 2018 年开始的杰出[大修](https://fpy.li/21-69)之后的[官方文档](https://fpy.li/21-1)，以及 Caleb Hattingh 的书 [*在 Python 中使用 asyn CIO*](https://fpy.li/hattingh)(O ' Reilly)。在官方文档中，请务必阅读[“使用 asyncio 开发”](https://fpy.li/21-70):记录 *asyncio* 调试模式，并讨论常见错误和陷阱以及如何避免它们。

关于非常容易理解的 30 分钟的异步编程介绍，以及 *asyncio* ，请观看 Miguel Grinberg 在 PyCon 2017 上发表的[“完全初学者的异步 Python”](https://fpy.li/21-71)。另一个很棒的介绍是由 Michael Kennedy 介绍的[“揭开 Python 的 Async 和 Await 关键字的神秘面纱”](https://fpy.li/21-72)，其中我了解到了[*【unsync】*](https://fpy.li/21-73)库，该库提供了一个装饰器，可以根据需要将协程、I/O 绑定函数和 CPU 绑定函数的执行委托给`asyncio`、`threading`或`multiprocessing`。

在 EuroPython 2019 上，Lynn Root——PyLadies 的全球领导者——展示了优秀的[“高级 asyncio:解决现实世界的生产问题”](https://fpy.li/21-75)，这是她在 Spotify 担任员工工程师使用 Python 的经验。

2020 年，ukasz Langa 录制了一系列关于 *asyncio* 的精彩视频，从[“学习 Python 的 asyn CIO # 1——异步生态系统”](https://fpy.li/21-76)开始。Langa 还为 PyCon 2020 制作了超级酷的视频[“AsyncIO+Music”](https://fpy.li/21-77)，不仅展示了 *asyncio* 在一个非常具体的面向事件的领域中的应用，还从头开始解释它。

另一个受面向事件编程支配的领域是嵌入式系统。这就是为什么 Damien George 在他的微控制器的 [*MicroPython*](https://fpy.li/21-78) 解释器中增加了对`async/await`的支持。在 PyCon Australia 2018 上，Matt Trentini 展示了 [*uasyncio*](https://fpy.li/21-79) 库，这是 *asyncio* 的子集，是 MicroPython 标准库的一部分。

对于 Python 中异步编程的更高层次思考，请阅读 Tom Christie 的博客文章[“Python 异步框架——超越开发者部落主义”](https://fpy.li/21-80)。

最后推荐[“你的功能是什么颜色？”](https://fpy.li/21-81)作者 Bob Nystrom，讨论了 JavaScript、Python、C#和其他语言中普通函数和异步函数的不兼容执行模型。剧透警告:Nystrom 的结论是，得到这个权利的语言是 Go，其中所有的函数都是相同的颜色。我喜欢这一点。但是我也认为 Nathaniel J. Smith 写[“Go 语句被认为是有害的”](https://fpy.li/21-66)的时候是有道理的。没有什么是完美的，并发编程总是很难。

 *[1]Videla&Williams，*Rabbit MQ in Action*(Manning)，第 4 章，“用 Rabbit 解决问题:编码和模式”，第 61 页。

[2] Selivanov 用 Python 实现了`async/await`，并编写了相关的 pep[492](https://fpy.li/pep492)、 [525](https://fpy.li/pep525) 、 [530](https://fpy.li/pep530) 。

^(3](ch21.xhtml#idm46582386163264-marker)) 这个规则有一个例外:如果你用`-m asyncio`选项运行 Python，你可以在`>>>`提示符下直接使用`await`来驱动一个本地协程。这在[“尝试 Python 的异步控制台”中有解释。

[4] 对不起，我无法抗拒。

在我写这篇文章的时候， [5] `true.dev`的价格是 360 美元/年。我看到`for.dev`已经注册，但是没有配置 DNS。

这个技巧一字不差地引用自科技评论人 Caleb Hattingh 的评论。谢谢凯勒。

感谢 Guto Maia，他在阅读本章的第一版草稿时注意到信号量的概念并没有被解释。

[8] 关于这一点的详细讨论可以在我在 python-tulip 组发起的一个主题中找到，标题是[“asyncio . as _ completed 还会有哪些未来？”](https://fpy.li/21-19)。Guido 作出了回应，并对`as_completed`的实现以及 *asyncio* 中期货和协同程序之间的密切关系给出了见解。

[9] 截屏中的方框问号并不是你正在阅读的书或电子书的缺陷。这是 U+101EC—PHAISTOS 圆盘符号 CAT 字符，我使用的终端中的字体中没有这个字符。费斯托斯圆盘是一件刻有象形文字的古代艺术品，发现于克里特岛。

[10] 代替*uvicon*，你可以使用另一个 ASGI 服务器，比如 *hypercorn* 或者 *Daphne* 。更多信息请参见官方 ASGI 文档[中关于实现](https://fpy.li/21-30)的页面。

[11] 感谢技术评论家 Miroslav ediv 在代码示例中强调了使用`pathlib`的好地方。

^(第十二章) 第八章[](https://fpy.li/21-31)*中提到的强制执行类型在运行时提示，用于数据验证。*

*[13] 问题#5535 截止到 2021 年 10 月，但是 Mypy 从那以后没有新的发布，所以错误依然存在。*

*技术评论家 Leonardo Rochael 指出，构建索引可以委托给另一个使用`supervisor`协程中的`loop.run_with_executor()`的线程，这样服务器就可以在构建索引时立即接受请求。这是事实，但是查询索引是这个服务器唯一做的事情，所以在这个例子中它不会是一个大的胜利。*

*[15] 这对于实验来说很棒，就像 Node.js 控制台一样。感谢 Yury Selivanov 对异步 Python 的又一个杰出贡献。*

*[16] 参见[RFC 6761—特殊用途域名](https://fpy.li/21-45)。*

*[17] 这与 JavaScript 相反，JavaScript 中的`async/await`是硬连线到内置的事件循环和运行时环境，即浏览器、Node.js 或 Deno。*

*[18] 这不同于经典协程的注释，如“经典协程的泛型类型提示”中所述。*

*[19] 视频:[《node . js 简介》](https://fpy.li/21-59)4:55。*

*[20] 在 Go 1.5 发布之前，使用单线程是默认设置。几年前，Go 已经因为支持高度并发的网络系统而赢得了当之无愧的声誉。另一个证据表明，并发不需要多线程或 CPU 内核。*

*不管技术选择如何，这可能是这个项目中最大的错误:涉众没有采用 MVP 方法——尽快交付最小可行的产品，然后以稳定的速度添加特性。***