<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> 

# 第十七章。迭代器、生成器、和经典协程

> 当我在程序中看到模式时，我认为这是麻烦的征兆。程序的形状应该只反映它需要解决的问题。代码中的任何其他规律性都是一个迹象，至少对我来说，表明我正在使用不够强大的抽象——我经常手工生成一些我需要编写的宏的扩展。
> 
> 保罗·格拉厄姆，Lisp 黑客兼风险投资家 [1]

迭代是数据处理的基础:程序将计算应用于数据序列，从像素到核苷酸。如果数据不适合内存，我们需要缓慢地获取项目*——一次一个，按需获取。迭代器就是这么做的。本章展示了如何将*迭代器*设计模式构建到 Python 语言中，因此您永远不需要手工编写代码。*

 *Python 中的每个标准集合都是*可迭代的*。一个*可迭代的*对象提供了一个*迭代器*，Python 使用它来支持如下操作:

*   `for`循环

*   列表、字典和集合理解

*   解包作业

*   集合实例的构造

此 章节涵盖以下主题:

*   Python 如何使用`iter()`内置函数处理可迭代对象

*   如何在 Python 中实现经典迭代器模式

*   如何用生成器函数或生成器表达式替换经典迭代器模式

*   一个生成器函数是如何详细工作的，有逐行的描述

*   利用标准库中的通用生成器函数

*   使用`yield from`表达式组合生成器

*   为什么生成器和经典协程看起来很像，但使用方式却非常不同，不应该混淆

# 本章的新内容

【产自】子代从一页增加到六页。现在，它包含了用`yield from`演示生成器行为的更简单的实验，以及一个逐步开发的遍历树数据结构的例子。

新的章节解释了`Iterable`、`Iterator`和`Generator`类型的类型提示。

本章的最后一个主要部分，“经典协程”，是一个主题的 9 页介绍，在第一版中占了 40 页。我更新了“经典协程”](https://fpy.li/oldcoro)一章，并将其移到了配套网站的[帖子中，因为这是对读者来说最具挑战性的一章，但在 Python 3.5 引入原生协程之后，它的主题就不那么相关了——我们将在](https://fpy.li/oldcoro)[第 21 章中研究这一点。

我们将开始研究`iter()`内置函数如何使序列可迭代。

# 一串单词

我们将 通过实现一个`Sentence`类来开始我们对 iterables 的探索:你给它的构造函数一个带有一些文本的字符串，然后你可以一个字一个字地迭代。第一个版本将实现序列协议，它是可迭代的，因为所有的序列都是可迭代的——正如我们从第 1 章开始看到的。现在我们来看看到底是为什么。

示例 17-1 显示了一个`Sentence`类，它通过索引从文本中提取单词。

##### 示例 17-1：作为一个单词序列

```
importreimportreprlibRE_WORD=re.compile(r'\w+')classSentence:def__init__(self,text):self.text=textself.words=RE_WORD.findall(text)①def__getitem__(self,index):returnself.words[index]②def__len__(self):③returnlen(self.words)def__repr__(self):return'Sentence(%s)'%reprlib.repr(self.text)④
```

① `.findall`以字符串列表的形式返回正则表达式中所有不重叠匹配的列表。

② `self.words`保存`.findall`的结果，所以我们只需返回给定索引处的单词。

③ 为了完成序列协议，我们实现了`__len__`,尽管不需要它来创建 iterable。

④ `reprlib.repr`是一个实用函数，用于生成可能非常大的数据结构的缩写字符串表示。 [2]

默认情况下，`reprlib.repr`将生成的字符串限制为 30 个字符。参见示例 17-2 中的控制台会话，了解如何使用`Sentence`。

##### 示例 17-2：在`Sentence`实例上测试迭代

```
>>> s=Sentence('"The time has come," the Walrus said,')①>>> sSentence('"The time ha... Walrus said,') ②>>> forwordins:③... print(word)The time has come the Walrus said >>> list(s)④['The', 'time', 'has', 'come', 'the', 'Walrus', 'said']
```

① 一个句子是由一个字符串创建的。

② 使用由`reprlib.repr`产生的`...`记录`__repr__`的输出。

③ `Sentence`实例是可迭代的；我们一会儿就知道为什么了。

④ 由于是可迭代的，`Sentence`对象可以用作构建列表和其他可迭代类型的输入。

在接下来的页面中，我们将开发其他通过示例 17-2 中测试的`Sentence`类。然而，示例 17-1 中的实现与其他的不同，因为它也是一个序列，所以你可以通过索引得到单词:

```
>>> s[0]
'The'
>>> s[5]
'Walrus'
>>> s[-1]
'said'
```

Python 程序员知道序列是可迭代的。现在我们来看看确切的原因。

# 为什么序列是可迭代的:迭代函数

每当 Python 需要迭代一个对象`x`时，就会自动调用`iter(x)`。

`iter`内置功能:

1.  检查对象是否实现了`__iter__`，并调用它来获得一个迭代器。

2.  如果`__iter__`没有实现，但是`__getitem__`实现了，那么`iter()`创建一个迭代器，尝试从 0(零)开始通过索引获取条目。

3.  如果失败，Python 会抛出`TypeError`，通常是说`'C' object is not iterable`，其中`C`是目标对象的类。

这就是为什么所有 Python 序列都是可迭代的:根据定义，它们都实现了`__getitem__`。事实上，标准序列也实现了`__iter__`，您的也应该实现，因为通过`__getitem__`的迭代是为了向后兼容而存在的，将来可能会消失——尽管从 Python 3.10 开始它没有被弃用，我怀疑它是否会被删除。

正如“Python 挖掘序列”中提到的，这是鸭子类型化的一种极端形式:一个对象不仅在实现特殊方法`__iter__`时被认为是可迭代的，在实现`__getitem__`时也被认为是可迭代的。看一看:

```
>>> class Spam:
...     def __getitem__(self, i):
...         print('->', i)
...         raise IndexError()
...
>>> spam_can = Spam()
>>> iter(spam_can)
<iterator object at 0x10a878f70>
>>> list(spam_can)
-> 0
[]
>>> from collections import abc
>>> isinstance(spam_can, abc.Iterable)
False
```

如果一个类提供了`__getitem__`，那么`iter()`内置接受该类的一个实例作为 iterable，并从该实例构建一个迭代器。Python 的迭代机制将调用索引从 0 开始的`__getitem__`，并将一个`IndexError`作为一个信号表示不再有条目。

请注意，尽管`spam_can`是可迭代的(它的`__getitem__`可以提供项目)，但它不会被`isinstance`识别为与`abc.Iterable`对抗。

在 goose-typing 方法中，对 iterable 的定义更简单，但是不够灵活:如果一个对象实现了`__iter__`方法，它就被认为是 iterable。不需要子类化或注册，因为`abc.Iterable`实现了`__subclasshook__`，如“使用 ABCs 的结构化分型”所示。下面是一个演示:

```
>>> class GooseSpam:
...     def __iter__(self):
...         pass
...
>>> from collections import abc
>>> issubclass(GooseSpam, abc.Iterable)
True
>>> goose_spam_can = GooseSpam()
>>> isinstance(goose_spam_can, abc.Iterable)
True
```

###### 小费

从 Python 3.10 开始，检查对象`x`是否可迭代的最准确方法是调用`iter(x)`并在不可迭代时处理一个`TypeError`异常。这比使用`isinstance(x, abc.Iterable)`更准确，因为`iter(x)`也考虑了遗留的 `__getitem__` 方法，而`Iterable` ABC 则没有。

显式检查一个对象是否是可迭代的可能不值得，如果在检查之后你要迭代这个对象。毕竟，当在不可改变的对象上尝试迭代时，Python 引发的异常是足够清楚的:`TypeError: 'C' object is not iterable`。如果您能做得比仅仅提高`TypeError`更好，那么在`try/except`块中这样做，而不是进行显式检查。如果您正保持对象以便稍后迭代它，显式检查可能是有意义的；在这种情况下，及早捕捉错误会使调试更容易。

Python 本身比我们自己的代码更经常使用内置的。我们还有第二种方法可以利用它，但并不广为人知。

## 将 iter 与可调用的

我们 可以用两个参数调用`iter()`来从一个函数或者任何可调用的对象创建一个迭代器。在这种用法中，第一个参数必须是可调用的，以便重复调用(不带参数)来产生值，第二个参数是一个[](https://fpy.li/17-2)*:一个标记值，当由可调用的返回时，它导致迭代器产生`StopIteration`而不是产生标记。*

 *以下示例显示了如何使用`iter`滚动六面模具，直到`1`被滚动:

```
>>> def d6():
...     return randint(1, 6)
...
>>> d6_iter = iter(d6, 1)
>>> d6_iter
<callable_iterator object at 0x10a245270>
>>> for roll in d6_iter:
...     print(roll)
...
4
3
6
3
```

注意这里的`iter`函数返回一个`callable_iterator`。示例中的`for`循环可能会运行很长时间，但它永远不会显示`1`，因为那是 sentinel 值。和迭代器一样，示例中的`d6_iter`对象一旦耗尽就变得无用。要重新开始，我们必须通过再次调用`iter()`来重建迭代器。

`iter` 的[文档包括以下解释和示例代码:](https://fpy.li/17-3)

> 第二种形式的`iter()`的一个有用应用是构建一个块阅读器。例如，从二进制数据库文件中读取固定宽度的块，直到到达文件末尾:

```
from functools import partial

with open('mydata.db', 'rb') as f:
    read64 = partial(f.read, 64)
    for block in iter(read64, b''):
        process_block(block)
```

为了清楚起见，我添加了`read64`赋值，它不在[原始示例](https://fpy.li/17-3)中。`partial()`函数是必需的，因为赋予`iter()`的可调用函数不需要参数。在这个例子中，一个空的`bytes`对象是 sentinel，因为当没有更多的字节可以读取时，这就是`f.read`返回的结果。

下一节将详细介绍可迭代对象和迭代器之间的关系。*  *# 可迭代与迭代器

从“为什么序列是可迭代的:iter 函数”中的解释我们可以推出一个定义:

iterable

`iter`内置函数可以从中获取迭代器的任何对象。实现返回迭代器*的`__iter__`方法的对象是可迭代的。序列总是可迭代的，实现接受基于 0 的索引的`__getitem__`方法的对象也是如此。*

清楚 iterables 和迭代器之间的关系很重要:Python 从 iterables 获得迭代器。

下面是一个简单的`for`循环，它迭代了一个`str`。这里的`str` `'ABC'`是可迭代的。您看不到它，但幕后有一个迭代器:

```
>>> s = 'ABC'
>>> for char in s:
...     print(char)
...
A
B
C
```

如果没有`for`语句，我们必须用一个`while`循环手动模拟`for`机制，那么我们必须这样写:

```
>>> s='ABC'>>> it=iter(s)①>>> whileTrue:... try:... print(next(it))②... exceptStopIteration:③... delit④... break⑤...A B C
```

① 从 iterable 构建一个迭代器`it`。

② 在迭代器上重复调用`next`获取下一项。

③ 当没有其他项目时，迭代器抛出`StopIteration`。

④ 释放对`it`的引用—迭代器对象被丢弃。

⑤ 退出循环。

`StopIteration`表示迭代器已经用尽。这个异常由内置的`iter()`在内部处理，它是`for`循环和其他迭代上下文(如列表理解、可迭代解包等)逻辑的一部分。

Python 的迭代器标准接口有两种方法:

`__next__`

返回序列中的下一个项目，如果没有更多项目，则引发`StopIteration`。

`__iter__`

返回`self`；这使得迭代器可以用在需要 iterable 的地方，例如在一个`for`循环中。

该接口在`collections.abc.Iterator` ABC 中被形式化，它声明了`__next__`抽象方法，并子类化了`Iterable`——在那里声明了抽象`__iter__`方法。参见图 17-1 。

![Iterable UML diagram](Images/flpy_1701.png)

###### 图 17-1。中的`Iterable`和`Iterator`ABC。斜体的方法是抽象的。具体的`Iterable.__iter__`应该返回一个新的`Iterator`实例。一个具体的`Iterator`必须实现`__next__`。`Iterator.__iter__`方法只返回实例本身。

`collections.abc.Iterator`的源代码在示例 17-3 中。

##### 示例 17-3：类`abc.Iterator`类；摘自[*Lib/_ collections _ ABC . py*](https://fpy.li/17-5)

```
classIterator(Iterable):__slots__=()@abstractmethoddef__next__(self):'Return the next item from the iterator. When exhausted, raise StopIteration'raiseStopIterationdef__iter__(self):returnself@classmethoddef__subclasshook__(cls,C):①ifclsisIterator:return_check_methods(C,'__iter__','__next__')②returnNotImplemented
```

① `__subclasshook__`支持用`isinstance`和`issubclass`进行结构型式检查。我们在“带 ABCs 的结构分型”中看到过。

② `_check_methods`遍历类的`__mro__`,检查方法是否在其基类中实现。它在同一个*Lib/_ collections _ ABC . py*模块中定义。如果实现了这些方法，`C`类将被识别为`Iterator`的虚拟子类。换句话说，`issubclass(C, Iterable)`会返回`True`。

###### 警告

`Iterator` ABC 抽象方法在 Python 3 中是`it.__next__()`，在 Python 2 中是`it.next()`。像往常一样，您应该避免直接调用特殊方法。只需使用`next(it)`:这个内置函数在 Python 2 和 3 中做正确的事情——这对那些从 2 到 3 移植代码库的人很有用。

Python 3.9 中的 [*Lib/types.py*](https://fpy.li/17-6) 模块源代码有一条注释说:

```
# Iterators in Python aren't a matter of type but of protocol.  A large
# and changing number of builtin types implement *some* flavor of
# iterator.  Don't check the type!  Use hasattr to check for both
# "__iter__" and "__next__" attributes instead.
```

事实上，这正是`abc.Iterator` ABC 的`__subclasshook__`方法所做的。

###### 小费

给定来自 *Lib/types.py* 的建议和在*Lib/_ collections _ ABC . py*中实现的逻辑，检查对象`x`是否是迭代器的最好方法是调用`isinstance(x, abc.Iterator)`。多亏了`Iterator.__subclasshook__`，即使`x`的类不是`Iterator`的真实或虚拟子类，这个测试也能工作。

从示例 17-1 回到我们的`Sentence`类，您可以清楚地看到迭代器是如何由`iter()`构建并由`next()`使用 Python 控制台消费的:

```
>>> s3=Sentence('Life of Brian')①>>> it=iter(s3)②>>> it# doctest: +ELLIPSIS<iterator object at 0x...> >>> next(it)③'Life' >>> next(it)'of' >>> next(it)'Brian' >>> next(it)④Traceback (most recent call last):
...StopIteration>>> list(it)⑤[] >>> list(iter(s3))⑥['Life', 'of', 'Brian']
```

① 用三个单词造一个句子`s3`。

② 从`s3`获取一个迭代器。

③ `next(it)`取下一个单词。

④ 没有更多的单词，所以迭代器引发了一个`StopIteration`异常。

⑤ 一旦耗尽，迭代器总是会抛出`StopIteration`，这使得它看起来像是空的。

⑥ 要再次检查句子，必须构建一个新的迭代器。

因为迭代器需要的方法只有`__next__`和`__iter__`，所以除了调用`next()`和捕捉`StopIteration`之外，没有其他方法可以检查是否还有剩余的项。同样，不可能“重置”一个迭代器。如果需要重新开始，需要在最初构建迭代器的 iterable 上调用`iter()`。在迭代器本身上调用`iter()`也不会有帮助，因为——如前所述——`Iterator.__iter__`是通过返回`self`实现的，所以这不会重置一个耗尽的迭代器。

这个最小接口是合理的，因为实际上不是所有的迭代器都是可重置的。例如，如果一个迭代器正在从网络上读取数据包，就没有办法倒带。 [3]

来自示例 17-1 的`Sentence`的第一个版本是可迭代的，这要归功于`iter()`内置给序列的特殊处理。接下来，我们将实现实现`__iter__`返回迭代器的`Sentence`变体。

# 带有 __iter__ 的句子类别

`Sentence`的 的下一个变体实现了标准的可迭代协议，首先通过实现迭代器设计模式，然后使用生成器函数。

## 第二句:经典的迭代器

下一个`Sentence`实现遵循了*设计模式*书中经典迭代器设计模式的蓝图。注意，它不是惯用的 Python，因为接下来的重构将会非常清楚。但是展示可迭代集合和使用它的迭代器之间的区别是很有用的。

示例 17-4 中的`Sentence`类是可迭代的，因为它实现了`__iter__`特殊方法，该方法构建并返回一个`SentenceIterator`。这就是 iterable 和 iterator 的关系。

##### 示例 17-4：句子 _iter.py: `Sentence`使用迭代器模式实现

```
importreimportreprlibRE_WORD=re.compile(r'\w+')classSentence:def__init__(self,text):self.text=textself.words=RE_WORD.findall(text)def__repr__(self):returnf'Sentence({reprlib.repr(self.text)})'def__iter__(self):①returnSentenceIterator(self.words)②classSentenceIterator:def__init__(self,words):self.words=words③self.index=0④def__next__(self):try:word=self.words[self.index]⑤exceptIndexError:raiseStopIteration()⑥self.index+=1⑦returnword⑧def__iter__(self):⑨returnself
```

① `__iter__`方法是对前面的`Sentence`实现的唯一补充。这个版本没有`__getitem__`，以明确这个类是可迭代的，因为它实现了`__iter__`。

② `__iter__`通过实例化并返回一个迭代器来实现 iterable 协议。

③ `SentenceIterator`保存对单词列表的引用。

④ `self.index`确定要读取的下一个单词。

⑤ 在`self.index`得到消息。

⑥ 如果`self.index`处没有字，抬起`StopIteration`。

⑦ 增量`self.index`。

⑧ 还字。

⑨ 执行`self.__iter__`。

示例 17-4 中的代码通过示例 17-2 中的测试。

请注意，在`SentenceIterator`中实现`__iter__`对于这个示例的工作来说并不真正需要，但是这样做是正确的:迭代器应该实现`__next__`和`__iter__`中的，这样做可以使我们的迭代器通过的`issubclass(SentenceIterator, abc.Iterator)`和测试。如果我们从`abc.Iterator`中继承了 `SentenceIterator` ，我们将继承具体的`abc.Iterator.__iter__`方法。

这是一项繁重的工作(无论如何，对于我们这些被宠坏的 Python 程序员来说)。注意`SentenceIterator`中的大多数代码是如何处理迭代器内部状态的。很快我们就会知道如何避免记账。但是首先，简单地绕一下路，解决一个可能很诱人但却是错误的实现捷径。

## 不要让 Iterable 成为自身的迭代器

构建 iterables 和 iterators 时出错的一个常见原因是混淆了这两者。需要明确的是:iterables 有一个`__iter__`方法，每次实例化一个新的迭代器。迭代器实现了一个返回单个项目的`__next__`方法和一个返回`self`的`__iter__`方法。

所以迭代器也是可迭代的，但是可迭代的不是迭代器。

除了在`Sentence`类中实现`__iter__`之外，还实现`__next__`可能很诱人，使每个`Sentence`实例同时成为自身的可迭代和迭代器。但这很少是个好主意。Alex Martelli 说，这也是一种常见的反模式，他在 Google 有很多审查 Python 代码的经验。

*设计模式*一书中关于迭代器设计模式的“适用性”部分说:

> 使用迭代器模式
> 
> *   在不暴露其内部表示的情况下访问聚合对象的内容。
>     
>     
> *   支持聚合对象的多次遍历。
>     
>     
> *   为遍历不同的聚合结构提供统一的接口(即支持多态迭代)。

为了“支持多个遍历”，必须有可能从同一个 iterable 实例中获得多个独立的迭代器，并且每个迭代器必须保持自己的内部状态，因此模式的正确实现需要每次调用`iter(my_iterable)`来创建一个新的独立迭代器。这就是为什么我们在这个例子中需要`SentenceIterator`类。

现在经典的迭代器模式已经被恰当地演示了，我们可以放手了。Python 结合了 Barbara Liskov 的 [CLU 语言](https://fpy.li/17-7)中的`yield`关键字，所以我们不需要“手工生成”代码来实现迭代器。

接下来的部分展示了`Sentence`的更多惯用版本。

## 第三句:一个生成器函数

相同功能的一个python 实现使用了一个生成器，避免了实现`SentenceIterator`类的所有工作。在示例 17-5 之后，将对发电机进行适当的解释。

##### 示例 17-5：使用生成器实现

```
importreimportreprlibRE_WORD=re.compile(r'\w+')classSentence:def__init__(self,text):self.text=textself.words=RE_WORD.findall(text)def__repr__(self):return'Sentence(%s)'%reprlib.repr(self.text)def__iter__(self):forwordinself.words:①yieldword②③# done! ④
```

① 迭代`self.words`。

② 产生电流`word`。

③ 显式`return`没有必要；该函数可以“失败”并自动返回。无论哪种方式，生成器函数都不会引发`StopIteration`:它只是在生成完值后退出。 [4]

④ 不需要单独的迭代器类！

这里我们又有一个不同的`Sentence`实现，它通过了示例 17-2 中的测试。

回到示例 17-4 中的`Sentence`代码，`__iter__`调用`SentenceIterator`构造函数构建一个迭代器并返回它。现在示例 17-5 中的迭代器实际上是一个生成器对象，在调用`__iter__`方法时自动构建，因为这里的`__iter__`是一个生成器函数。

发电机的完整解释如下。

## 发电机是如何工作的

任何主体中包含`yield`关键字的 Python 函数都是一个生成器函数:一个被调用时返回一个生成器对象的函数。换句话说，一个生成器函数就是一个生成器工厂。

###### 小费

区别普通函数和生成器函数的唯一语法是，后者在其主体的某个地方有一个`yield`关键字。一些人认为应该使用一个新的关键字，比如`gen`，而不是`def`，来声明生成器函数，但是 Guido 不同意。他的论点在 PEP 255 中——简单的生成器。 [5]

示例 17-6 显示了一个简单的发生器函数的行为。 [6]

##### 示例 17-6：产生三个数的发生器函数

```
>>> def gen_123():
...     yield 1  ①
...     yield 2
...     yield 3
...
>>> gen_123  # doctest: +ELLIPSIS
<function gen_123 at 0x...>  ②
>>> gen_123()   # doctest: +ELLIPSIS
<generator object gen_123 at 0x...>  ③
>>> for i in gen_123():  ④
...     print(i)
1
2
3
>>> g = gen_123()  ⑤
>>> next(g)  ⑥
1
>>> next(g)
2
>>> next(g)
3
>>> next(g)  ⑦
Traceback (most recent call last):
  ...
StopIteration
```

① 一个生成器函数的主体经常在一个循环里面有`yield`，但不一定；这里我只重复`yield`三遍。

② 仔细看，我们看到`gen_123`是一个函数对象。

③ 但是当被调用时，`gen_123()`返回一个生成器对象。

④ 生成器对象实现了`Iterator`接口，所以它们也是可迭代的。

⑤ 我们将这个新的生成器对象分配给`g`，因此我们可以对它进行实验。

⑥ 因为`g`是一个迭代器，调用`next(g)`获取`yield`产生的下一个项目。

⑦ 当生成器函数返回时，生成器对象引发`StopIteration`。

生成器函数构建一个包装函数体的生成器对象。当我们在生成器对象上调用`next()`时，执行前进到函数体中的下一个`yield`，并且`next()`调用评估函数体挂起时产生的值。最后，根据`Iterator`协议，Python 创建的封闭生成器对象在函数体返回时引发`StopIteration`。

###### 小费

我发现在讨论从生成器中获得的值时，保持严谨是有帮助的。说生成器“返回”值是令人困惑的。函数返回值。调用生成器函数会返回一个生成器。生成器产生值。生成器不会以通常的方式“返回”值:生成器函数体中的`return`语句导致`StopIteration`被生成器对象引发。如果您在生成器中`return x`，调用者可以从`StopIteration`异常中检索`x`的值，但是通常这是使用`yield from`语法自动完成的，我们将在“从协程返回值”中看到。

示例 17-7 使得`for`循环和函数体之间的交互更加清晰。

##### 示例 17-7：运行时打印消息的生成器功能

```
>>> defgen_AB():... print('start')... yield'A'①... print('continue')... yield'B'②... print('end.')③...>>> forcingen_AB():④... print('-->',c)⑤...start ⑥--> A ⑦continue ⑧--> B ⑨end. ⑩>>> ⑪
```

① 在④处第一次隐式调用`for`循环中的`next()`将打印`'start'`并在第一个`yield`处停止，产生值`'A'`。

② 在`for`循环中对`next()`的第二次隐式调用将打印`'continue'`并在第二个`yield`处停止，产生值`'B'`。

③ 对`next()`的第三次调用将打印`'end.'`并穿过函数体的末端，导致生成器对象升高`StopIteration`。

④ 为了进行迭代，`for`机器执行与`g = iter(gen_AB())`相同的操作来获得一个生成器对象，然后在每次迭代中执行`next(g)`。

⑤ 循环打印`-->`和`next(g)`返回的值。只有在发生器函数内部调用`print`的输出后，该输出才会出现。

⑥ 文本`start`来自发生器本体中的`print('start')`。

⑦ 发生器主体中的`yield 'A'`产生由`for`循环消耗的值 *A* ，该值被分配给`c`变量并产生输出`--> A`。

⑧ 通过第二次调用`next(g)`继续迭代，将发生器主体从`yield 'A'`推进到`yield 'B'`。文本`continue`由发生器体内的第二个`print`输出。

⑨ `yield 'B'`产生由`for`循环消耗的值 *B* ，该值被分配给`c`循环变量，因此循环打印`--> B`。

⑩ 迭代继续，第三次调用`next(it)`，前进到函数体的末尾。文本`end.`出现在输出中，因为发生器主体中有第三个`print`。

⑪ 当生成器函数运行到最后，生成器对象引发`StopIteration`。`for`循环机制捕获该异常，循环干净地终止。

现在希望能清楚示例 17-5 中的`Sentence.__iter__`是如何工作的:`__iter__`是一个生成器函数，当被调用时，它构建一个实现`Iterator`接口的生成器对象，所以不再需要`SentenceIterator`类。

第二个版本的`Sentence`比第一个更简洁，但是它并没有想象中的那么懒惰。现在，懒惰被认为是一种好的品质，至少在编程语言和 API 中是这样。一个懒惰的实现把产生值推迟到最后一刻。这可以节省内存，也可以避免浪费 CPU 周期。

接下来我们将构建懒惰的`Sentence`类。

# 懒惰的句子

`Sentence`的 最终版本是惰性的，利用了`re`模块的惰性函数。

## 第四句:懒惰的发电机

`Iterator`接口被设计成惰性的:`next(my_iterator)`一次产生一个项目。懒惰的反义词是渴望:懒惰求值和渴望求值是编程语言理论中的专业术语。

到目前为止，我们的`Sentence`实现并不懒惰，因为`__init__`急切地构建文本中所有单词的列表，并将其绑定到`self.words`属性。这需要处理整个文本，列表使用的内存可能和文本本身一样多(可能更多；这取决于文本中有多少非单词字符)。如果用户只重复前几个单词，大部分工作都是徒劳的。如果你想知道，“在 Python 中有没有一种懒惰的方式来做到这一点？”答案往往是“是的”。

`re.finditer`函数是`re.findall`的一个懒惰版本。`re.finditer`返回的不是列表，而是按需生成`re.MatchObject`实例的生成器。如果有很多匹配，`re.finditer`会节省很多内存。使用它，我们的第三个版本`Sentence`现在变懒了:它只在需要的时候从文本中读取下一个单词。代码在示例 17-8 中。

##### 示例 17-8： sentence_gen2.py: `Sentence`使用调用`re.finditer`生成器函数的生成器函数实现

```
importreimportreprlibRE_WORD=re.compile(r'\w+')classSentence:def__init__(self,text):self.text=text①def__repr__(self):returnf'Sentence({reprlib.repr(self.text)})'def__iter__(self):formatchinRE_WORD.finditer(self.text):②yieldmatch.group()③
```

① 不需要有`words`名单。

② `finditer`在`self.text`的`RE_WORD`匹配上构建一个迭代器，产生`MatchObject`实例。

③ `match.group()`从`MatchObject`实例中提取匹配的文本。

生成器是一个很好的捷径，但是使用生成器表达式可以使代码更加简洁。

## 第五句:懒惰的生成器表达式

我们可以用一个生成器表达式替换简单的生成器函数，就像前面的`Sentence`类中的函数一样。正如列表理解构建列表一样，生成器表达式构建生成器对象。示例 17-9 对比了他们的行为。

##### 示例 17-9：`gen_AB`生成器函数由列表理解使用，然后由生成器表达式使用

```
>>> defgen_AB():①... print('start')... yield'A'... print('continue')... yield'B'... print('end.')...>>> res1=[x*3forxingen_AB()]②start continue end. >>> foriinres1:③... print('-->',i)...--> AAA --> BBB >>> res2=(x*3forxingen_AB())④>>> res2<generator object <genexpr> at 0x10063c240> >>> foriinres2:⑤... print('-->',i)...start ⑥--> AAA continue --> BBB end.
```

① 这与示例 17-7 中的`gen_AB`功能相同。

② 列表理解急切地迭代由`gen_AB()` : `'A'`和`'B'`返回的生成器对象产生的项目。注意接下来几行中的输出:`start`、`continue`、`end.`

③ 这个`for`循环遍历由列表理解构建的`res1`列表。

④ 生成器表达式返回一个生成器对象`res2`。这里不消耗发电机。

⑤ 只有当`for`循环遍历`res2`时，这个生成器才会从`gen_AB`获取项目。`for`循环的每一次迭代都隐式调用`next(res2)`，后者又对`gen_AB()`返回的生成器对象调用`next()`，将其推进到下一个`yield`。

⑥ 注意`gen_AB()`的输出如何与`for`回路中`print`的输出交错。

我们可以使用生成器表达式来进一步减少`Sentence`类中的代码。参见示例 17-10 。

##### 示例 17-10：句子 _ 基因 xp.py: `Sentence`使用生成器表达式实现

```
import re
import reprlib

RE_WORD = re.compile(r'\w+')

class Sentence:

    def __init__(self, text):
        self.text = text

    def __repr__(self):
        return f'Sentence({reprlib.repr(self.text)})'

    def __iter__(self):
        return (match.group() for match in RE_WORD.finditer(self.text))
```

与示例 17-8 唯一不同的是`__iter__`方法，这里不是一个生成器函数(它没有`yield`)而是使用一个生成器表达式来构建一个生成器，然后返回它。最终结果是一样的:`__iter__`的调用者得到一个生成器对象。

生成器表达式是语法糖:它们总是可以被生成器函数替换，但有时更方便。下一节是关于生成器表达式的用法。

# 何时使用生成器表达式

我 在示例 12-16 中实现`Vector`类时使用了几个生成器表达式。这些方法中的每一个都有一个生成器表达式:`__eq__`、`__hash__`、`__abs__`、`angle`、`angles`、、`format`、`__add__`和`__mul__`。在所有这些方法中，列表理解也可以工作，代价是使用更多的内存来存储中间列表值。

在示例 17-10 中，我们看到了生成器表达式是一种语法快捷方式，可以在不定义和调用函数的情况下创建生成器。另一方面，生成器函数更加灵活:我们可以用多条语句编写复杂的逻辑，我们甚至可以将它们用作*协程*，正如我们将在“经典协程”中看到的。

对于更简单的情况，生成器表达式更容易一目了然，如 `Vector` 示例所示。

我选择要使用的语法的经验法则很简单:如果生成器表达式跨越多行，为了可读性，我更喜欢编写一个生成器函数。

# 语法提示

当生成器表达式作为单个参数传递给函数或构造函数时，您不需要为函数调用编写一组括号，也不需要为生成器表达式编写另一组括号。一对就够了，就像在示例 12-16 中`__mul__`方法的`Vector`调用中一样，这里复制:

```
def __mul__(self, scalar):
    if isinstance(scalar, numbers.Real):
        return Vector(n * scalar for n in self)
    else:
        return NotImplemented
```

但是，如果在生成器表达式后面有更多的函数参数，就需要用括号将它括起来，以避免出现`SyntaxError`。

我们看到的`Sentence`例子演示了扮演经典迭代器模式角色的生成器:从集合中检索项目。但是我们也可以使用生成器来生成独立于数据源的值。下一节将展示一个例子。

但是首先，简短讨论一下*迭代器*和*生成器*的重叠概念。

# 算术级数生成器

经典迭代器模式都是关于遍历的:导航一些数据结构。但是，当项目是动态生成的，而不是从集合中检索时，基于获取系列中下一个项目的方法的标准接口也很有用。例如，`range`内置生成整数的有界算术级数(AP)。如果您需要生成任何类型的数字的 AP，而不仅仅是整数，该怎么办？

示例 17-11 显示了一个`ArithmeticProgression`类的几个控制台测试，我们稍后会看到。示例 17-11 中的构造者签名为`ArithmeticProgression(begin, step[, end])`。`range`内置的完整签名是`range(start, stop[, step])`。我选择实现不同的签名，因为在算术级数中`step`是强制的，而`end`是可选的。我还将参数名从`start/stop`改为`begin/end`，以表明我选择了不同的签名。在示例 17-11 的每个测试中，我对结果调用`list()`来检查生成的值。

##### 示例 17-11：一个`ArithmeticProgression`类的演示

```
    >>> ap = ArithmeticProgression(0, 1, 3)
    >>> list(ap)
    [0, 1, 2]
    >>> ap = ArithmeticProgression(1, .5, 3)
    >>> list(ap)
    [1.0, 1.5, 2.0, 2.5]
    >>> ap = ArithmeticProgression(0, 1/3, 1)
    >>> list(ap)
    [0.0, 0.3333333333333333, 0.6666666666666666]
    >>> from fractions import Fraction
    >>> ap = ArithmeticProgression(0, Fraction(1, 3), 1)
    >>> list(ap)
    [Fraction(0, 1), Fraction(1, 3), Fraction(2, 3)]
    >>> from decimal import Decimal
    >>> ap = ArithmeticProgression(0, Decimal('.1'), .3)
    >>> list(ap)
    [Decimal('0'), Decimal('0.1'), Decimal('0.2')]
```

注意，根据 Python 算术的数字强制规则，结果算术级数中的数字类型遵循`begin + step`的类型。在示例 17-11 中，您可以看到`int`、`float`、`Fraction`和`Decimal`编号列表。示例 17-12 列出了`ArithmeticProgression`类的实现。

##### 示例 17-12：本`ArithmeticProgression`类

```
classArithmeticProgression:def__init__(self,begin,step,end=None):①self.begin=beginself.step=stepself.end=end# None -> "infinite" seriesdef__iter__(self):result_type=type(self.begin+self.step)②result=result_type(self.begin)③forever=self.endisNone④index=0whileforeverorresult<self.end:⑤yieldresult⑥index+=1result=self.begin+self.step*index⑦
```

① `__init__`需要两个参数:`begin`和`step`；`end`是可选的，如果是`None`，系列将是无界的。

② 得到添加`self.begin`和`self.step`的类型。比如一个是`int`，一个是`float`，那么`result_type`就会是`float`。

③ 该行生成一个具有相同数值`self.begin`的`result`，但被强制为后续加法的类型。 [7]

④ 为了可读性，如果`self.end`属性为`None`，则`forever`标志将为`True`，从而产生一个无界序列。

⑤ 该循环运行`forever`或直到结果匹配或超过`self.end`。当这个循环退出时，函数也退出。

⑥ 目前的`result`正在生产。

⑦ 计算下一个可能的结果。它可能永远不会被放弃，因为`while`循环可能会终止。

在示例 17-12 的最后一行，我选择忽略之前的`result`和每个新的`result`，将`self.begin`加到`self.step`乘以`index`，而不是每次循环都将`self.step`加到之前的`result`。这避免了连续加法后浮点误差的累积效应。这些简单的实验清楚地表明了区别:

```
>>> 100 * 1.1
110.00000000000001
>>> sum(1.1 for _ in range(100))
109.99999999999982
>>> 1000 * 1.1
1100.0
>>> sum(1.1 for _ in range(1000))
1100.0000000000086
```

来自示例 17-12 的`ArithmeticProgression`类按预期工作，并且是使用生成器函数实现`__iter__`特殊方法的另一个例子。然而，如果一个类的全部目的是通过实现`__iter__`来构建一个生成器，我们可以用一个生成器函数来替换这个类。一个发电机功能毕竟是发电机厂。

示例 17-13 显示了一个名为`aritprog_gen`的生成器函数，它的功能与`ArithmeticProgression`相同，但代码更少。如果你只是调用`aritprog_gen`而不是`ArithmeticProgression`，那么示例 17-11 中的测试都通过。 [8]

##### 示例 17-13：`aritprog_gen`发电机功能

```
def aritprog_gen(begin, step, end=None):
    result = type(begin + step)(begin)
    forever = end is None
    index = 0
    while forever or result < end:
        yield result
        index += 1
        result = begin + step * index
```

示例 17-13 很优雅，但请永远记住:标准库中有大量现成的生成器，下一节将展示一个使用`itertools`模块的较短实现。

## 使用 itertools 的算术级数

Python 3.10 中的 `itertools`模块有 20 个生成器函数，可以用各种有趣的方式组合。

例如，`itertools.count`函数返回一个生成数字的生成器。如果没有参数，它会产生一系列以`0`开头的整数。但是您可以提供可选的`start`和`step`值来实现类似于我们的`aritprog_gen` 函数的结果:

```
>>> import itertools
>>> gen = itertools.count(1, .5)
>>> next(gen)
1
>>> next(gen)
1.5
>>> next(gen)
2.0
>>> next(gen)
2.5
```

###### 警告

`itertools.count`永不停止，所以如果你调用`list(count())`，Python 会尝试构建一个`list`来填充所有的内存芯片。实际上，在通话失败之前很久，你的机器就会变得非常暴躁。

另一方面，有一个`itertools.takewhile`函数:它返回一个使用另一个生成器的生成器，并在给定谓词的计算结果为`False`时停止。所以我们可以把两者结合起来，写成这样:

```
>>> gen = itertools.takewhile(lambda n: n < 3, itertools.count(1, .5))
>>> list(gen)
[1, 1.5, 2.0, 2.5]
```

利用`takewhile`和`count`、示例 17-14 更加简洁。

##### 示例 17-14：这就像之前的`aritprog_gen`函数一样

```
import itertools

def aritprog_gen(begin, step, end=None):
    first = type(begin + step)(begin)
    ap_gen = itertools.count(first, step)
    if end is None:
        return ap_gen
    return itertools.takewhile(lambda n: n < end, ap_gen)
```

注意示例 17-14 中的`aritprog_gen`不是一个发生器函数:它本身没有`yield`。但是它返回一个生成器，就像生成器函数一样。

但是，回想一下`itertools.count`重复添加`step`，所以它产生的浮点序列不如示例 17-13 精确。

例子 17-14 的要点是:当实现生成器时，要知道标准库中有什么，否则你很可能要重新发明轮子。这就是为什么下一节将介绍几个现成的生成器函数。

# 标准库中的生成器函数

标准库提供了许多生成器，从提供逐行迭代的纯文本文件对象，到令人惊叹的 [`os.walk`](https://fpy.li/17-12) 函数，该函数在遍历目录树时生成文件名，使得递归文件系统搜索像`for`循环一样简单。

`os.walk`生成器函数令人印象深刻，但是在这一节中，我想把重点放在通用函数上，这些函数将任意的可迭代项作为参数，并返回生成选定的、计算的或重新排列的项的生成器。在下面的表格中，我总结了来自内置、`itertools`和`functools`模块的 24 个模块。为了方便起见，我按照高级功能对它们进行了分组，而不管它们是在哪里定义的。

第一组包含过滤生成器函数:它们产生由输入 iterable 生成的项目的子集，而不改变项目本身。与`takewhile`一样，表 17-1 中列出的大多数函数都采用一个`predicate`，它是一个单参数布尔函数，将应用于输入中的每一项，以确定该项是否包含在输出中。

Table 17-1\. Filtering generator functions

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| `itertools` | T0 | 并行消耗两个 iterables 每当`selector_it`中的相应项目为真时，就产生来自`it`的项目 |
| `itertools` | `dropwhile(predicate, it)` | 消耗`it`，跳过项目，同时`predicate`计算真值，然后产生每个剩余项目(不做进一步检查) |
| (内置) | `filter(predicate, it)` | 将`predicate`应用于`iterable`的每一项，如果`predicate(item)`为真，则产生该项；如果`predicate`为`None`，则只产生真值项目 |
| `itertools` | `filterfalse(predicate, it)` | 与`filter`相同，与`predicate`逻辑相反:每当`predicate`计算 falsy 时产生项目 |
| `itertools` | `islice(it, stop) or islice(it, start, stop, step=1)` | 从一片`it`中产生项目，类似于`s[:stop]`或`s[start:stop:step]`，除了`it`可以是任何可迭代的，并且操作是懒惰的 |
| `itertools` | `takewhile(predicate, it)` | 在`predicate`计算真值时产生项目，然后停止，不做进一步检查 |

示例 17-15 中的控制台列表显示了表 17-1 中所有功能的使用。

##### 示例 17-15：过滤生成器功能示例

```
>>> def vowel(c):
...     return c.lower() in 'aeiou'
...
>>> list(filter(vowel, 'Aardvark'))
['A', 'a', 'a']
>>> import itertools
>>> list(itertools.filterfalse(vowel, 'Aardvark'))
['r', 'd', 'v', 'r', 'k']
>>> list(itertools.dropwhile(vowel, 'Aardvark'))
['r', 'd', 'v', 'a', 'r', 'k']
>>> list(itertools.takewhile(vowel, 'Aardvark'))
['A', 'a']
>>> list(itertools.compress('Aardvark', (1, 0, 1, 1, 0, 1)))
['A', 'r', 'd', 'a']
>>> list(itertools.islice('Aardvark', 4))
['A', 'a', 'r', 'd']
>>> list(itertools.islice('Aardvark', 4, 7))
['v', 'a', 'r']
>>> list(itertools.islice('Aardvark', 1, 7, 2))
['a', 'd', 'a']
```

下一组包含映射生成器:它们产生从输入 iterable——或者 iterables，在`map`和`starmap`的情况下——中的每个单独项目计算的项目。^(9](ch17.xhtml#idm46582403237584))[表 17-2 中的生成器为输入可重复项中的每一项生成一个结果。如果输入来自多个 iterable，则第一个输入 iterable 一用完，输出就停止。

Table 17-2\. Mapping generator functions

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| `itertools` | `accumulate(it, [func])` | 产生累积的总和；如果提供了`func`，则产生将其应用于第一对项目的结果，然后应用于第一个结果和下一个项目，依此类推。 |
| (内置) | `enumerate(iterable, start=0)` | 产生形式为`(index, item)`的二元组，其中`index`从`start`开始计数，`item`从`iterable`开始计数 |
| (内置) | `map(func, it1, [it2, …, itN])` | 将`func`应用于`it`的每一项，产生结果；如果给定了 N 个可迭代对象，`func`必须接受 N 个参数，这些可迭代对象将被并行使用 |
| `itertools` | `starmap(func, it)` | 将`func`应用于`it`的每一项，产生结果；输入 iterable 应该产生 iterable items `iit`，并且`func`被应用为`func(*iit)` |

示例 17-16 演示了`itertools.accumulate`的一些用法。

##### 示例 17-16： `itertools.accumulate`生成器功能示例

```
>>> sample=[5,4,2,8,7,6,3,0,9,1]>>> importitertools>>> list(itertools.accumulate(sample))①[5, 9, 11, 19, 26, 32, 35, 35, 44, 45] >>> list(itertools.accumulate(sample,min))②[5, 4, 2, 2, 2, 2, 2, 0, 0, 0] >>> list(itertools.accumulate(sample,max))③[5, 5, 5, 8, 8, 8, 8, 8, 9, 9] >>> importoperator>>> list(itertools.accumulate(sample,operator.mul))④[5, 20, 40, 320, 2240, 13440, 40320, 0, 0, 0] >>> list(itertools.accumulate(range(1,11),operator.mul))[1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800] ⑤
```

① 运行总和。

② 运行最小值。

③ 运行最大值。

④ 运行产品。

⑤ 从`1!`到`10!`的阶乘。

表 17-2 的其余功能如示例 17-17 所示。

##### 示例 17-17：映射生成器功能示例

```
>>> list(enumerate('albatroz',1))①[(1, 'a'), (2, 'l'), (3, 'b'), (4, 'a'), (5, 't'), (6, 'r'), (7, 'o'), (8, 'z')] >>> importoperator>>> list(map(operator.mul,range(11),range(11)))②[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100] >>> list(map(operator.mul,range(11),[2,4,8]))③[0, 4, 16] >>> list(map(lambdaa,b:(a,b),range(11),[2,4,8]))④[(0, 2), (1, 4), (2, 8)] >>> importitertools>>> list(itertools.starmap(operator.mul,enumerate('albatroz',1)))⑤['a', 'll', 'bbb', 'aaaa', 'ttttt', 'rrrrrr', 'ooooooo', 'zzzzzzzz'] >>> sample=[5,4,2,8,7,6,3,0,9,1]>>> list(itertools.starmap(lambdaa,b:b/a,... enumerate(itertools.accumulate(sample),1)))⑥[5.0, 4.5, 3.6666666666666665, 4.75, 5.2, 5.333333333333333, 5.0, 4.375, 4.888888888888889, 4.5]
```

① 给单词中的字母编号，从`1`开始。

② 从`0`到`10`的整数的平方。

③ 并行地将两个可迭代的数相乘:当最短的可迭代结束时，结果停止。

④ 这就是`zip`内置函数的作用。

⑤ 从`1`开始，根据字母在单词中的位置重复单词中的每个字母。

⑥ 运行平均值。

接下来，我们有一组合并生成器——所有这些都从多个输入可重复项中产生项目。`chain`和`chain.from_iterable`顺序消耗输入的可重复项(一个接一个)，而`product`、`zip`和`zip_longest`并行消耗输入的可重复项。参见表 17-3 。

Table 17-3\. Generator functions that merge multiple input iterables

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| `itertools` | `chain(it1, …, itN)` | 从`it1`产生所有项目，然后从`it2`产生，依此类推。，无缝 |
| `itertools` | `chain.from_iterable(it)` | 无缝地从`it`产生的每个 iterable 中一个接一个地产生所有项目；`it`将是可迭代的，其中项目也是可迭代的，例如，元组列表 |
| `itertools` | `product(it1, …, itN, repeat=1)` | 笛卡尔积:通过组合来自每个输入 iterable 的项产生 N 元组，就像嵌套的`for`循环可以产生的那样；`repeat`允许输入的可重复项被多次使用 |
| (内置) | `zip(it1, …, itN, strict=False)` | 产生从并行的可迭代对象中提取的项目构建的 N 元组，当第一个可迭代对象用尽时，自动停止，除非给`strict=True`一个 ^(一个) |
| `itertools` | `zip_longest(it1, …, itN, fillvalue=None)` | 产生 N 元组，这些元组是从并行的可迭代项中提取的项构建的，仅当最后一个可迭代项用尽时才停止，用`fillvalue`填充空白 |
| [a]`strict`唯关键字参数是 Python 3.10 中的新增功能。当`strict=True`时，如果任何 iterable 的长度不同，则`ValueError`被引发。为了向后兼容，默认为`False`。 |

示例 17-18 显示了`itertools.chain`和`zip`发生器功能及其同级功能的使用。回想一下`zip`功能是以拉链或拉链命名的(与压缩无关)。`zip`和`itertools.zip_longest`都是在《牛逼拉链》中介绍的。

##### 示例 17-18：合并生成器功能示例

```
>>> list(itertools.chain('ABC',range(2)))①['A', 'B', 'C', 0, 1] >>> list(itertools.chain(enumerate('ABC')))②[(0, 'A'), (1, 'B'), (2, 'C')] >>> list(itertools.chain.from_iterable(enumerate('ABC')))③[0, 'A', 1, 'B', 2, 'C'] >>> list(zip('ABC',range(5),[10,20,30,40]))④[('A', 0, 10), ('B', 1, 20), ('C', 2, 30)] >>> list(itertools.zip_longest('ABC',range(5)))⑤[('A', 0), ('B', 1), ('C', 2), (None, 3), (None, 4)] >>> list(itertools.zip_longest('ABC',range(5),fillvalue='?'))⑥[('A', 0), ('B', 1), ('C', 2), ('?', 3), ('?', 4)]
```

① `chain`通常用两个或多个 iterables 调用。

② `chain`用单个 iterable 调用时没有任何用处。

③ 但是`chain.from_iterable`从 iterable 中取出每一项，并按顺序链接它们，只要每一项本身是 iterable。

④ `zip`可以并行消耗任意数量的可迭代程序，但是一旦第一个可迭代程序结束，生成器就会停止。在 Python ≥ 3.10 中，如果给定了`strict=True`参数，并且一个 iterable 在其他 iterable 之前结束，则会引发`ValueError`。

⑤ `itertools.zip_longest`的工作方式类似于`zip`，除了它消耗完所有的输入可重复项，根据需要用`None`填充输出元组。

⑥ `fillvalue`关键字参数指定一个自定义填充值。

`itertools.product`生成器是一种计算笛卡尔积的懒惰方法，它是我们使用列表理解在 “笛卡尔积”](ch02.xhtml#cartesian_product_sec)中用一个以上的`for`子句构建的。带有多个`for`子句的生成器表达式也可以用来生成笛卡尔乘积。[示例 17-19 演示。

##### 示例 17-19： `itertools.product`生成器功能示例

```
>>> list(itertools.product('ABC',range(2)))①[('A', 0), ('A', 1), ('B', 0), ('B', 1), ('C', 0), ('C', 1)] >>> suits='spades hearts diamonds clubs'.split()>>> list(itertools.product('AK',suits))②[('A', 'spades'), ('A', 'hearts'), ('A', 'diamonds'), ('A', 'clubs'), ('K', 'spades'), ('K', 'hearts'), ('K', 'diamonds'), ('K', 'clubs')] >>> list(itertools.product('ABC'))③[('A',), ('B',), ('C',)] >>> list(itertools.product('ABC',repeat=2))④[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] >>> list(itertools.product(range(2),repeat=3))[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)] >>> rows=itertools.product('AB',range(2),repeat=2)>>> forrowinrows:print(row)...('A', 0, 'A', 0) ('A', 0, 'A', 1) ('A', 0, 'B', 0) ('A', 0, 'B', 1) ('A', 1, 'A', 0) ('A', 1, 'A', 1) ('A', 1, 'B', 0) ('A', 1, 'B', 1) ('B', 0, 'A', 0) ('B', 0, 'A', 1) ('B', 0, 'B', 0) ('B', 0, 'B', 1) ('B', 1, 'A', 0) ('B', 1, 'A', 1) ('B', 1, 'B', 0) ('B', 1, 'B', 1)
```

① 一个有三个字符的`str`和一个有两个整数的`range`的笛卡尔积产生六元组(因为`3 * 2`是`6`)。

② 两个牌阶(`'AK'`)和四个花色的乘积就是一个八元组的数列。

③ 给定一个 iterable，`product`产生一系列一元组——不是很有用。

④ `repeat=N`关键字参数告诉产品消耗每个输入 iterable `N`次。

一些生成器函数通过为每个输入项生成多个值来扩展输入。它们列于表 17-4 中。

Table 17-4\. Generator functions that expand each input item into multiple output items

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| `itertools` | `combinations(it, out_len)` | 从`it`产生的项目中产生`out_len`项目的组合 |
| `itertools` | `combinations_with_replacement(it, out_len)` | 从由`it`产生的项目中产生`out_len`项目的组合，包括具有重复项目的组合 |
| `itertools` | `count(start=0, step=1)` | 产生从`start`开始的数字，以`step`递增，无限期 |
| `itertools` | `cycle(it)` | 从`it`产生项目，存储每个项目的副本，然后重复产生整个序列，无限期 |
| `itertools` | `pairwise(it)` | 从输入迭代 [a] 中产生连续的重叠对 |
| `itertools` | `permutations(it, out_len=None)` | 从由`it`产生的项目中产生`out_len`项目的排列；默认情况下，`out_len`是`len(list(it))` |
| `itertools` | `repeat(item, [times])` | 除非给出一个数字`times`,否则无限期地重复产生给定的项目 |
| ^(Python 3.10 中增加了一个) `itertools.pairwise`。 |

来自`itertools`的`count`和`repeat`函数返回无中生有的生成器:它们都不接受 iterable 作为输入。我们在“使用 itertools 的等差数列”中看到了`itertools.count`。`cycle` 生成器对输入 iterable 进行备份，并重复生成其项目。示例 17-20 说明了`count`、`cycle`、`pairwise`和`repeat`的用法。

##### 示例 17-20：、`count`、`cycle`、`pairwise`和`repeat`

```
>>> ct=itertools.count()①>>> next(ct)②0 >>> next(ct),next(ct),next(ct)③(1, 2, 3) >>> list(itertools.islice(itertools.count(1,.3),3))④[1, 1.3, 1.6] >>> cy=itertools.cycle('ABC')⑤>>> next(cy)'A' >>> list(itertools.islice(cy,7))⑥['B', 'C', 'A', 'B', 'C', 'A', 'B'] >>> list(itertools.pairwise(range(7)))⑦[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6)] >>> rp=itertools.repeat(7)⑧>>> next(rp),next(rp)(7, 7) >>> list(itertools.repeat(8,4))⑨[8, 8, 8, 8] >>> list(map(operator.mul,range(11),itertools.repeat(5)))⑩[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]
```

① 建造一个`count`发电机`ct`。

② 从`ct`处取回第一件物品。

③ 我不能从`ct`构建一个`list`，因为`ct`永远不会停止，所以我取接下来的三个项目。

④ 如果受到`islice`或`takewhile`的限制，我可以从`count`发电机造一个`list`。

⑤ 从`'ABC'`建造一个`cycle`生成器，并获取它的第一个物品`'A'`。

⑥ 一个`list`只有受到`islice`的限制才能建造；接下来的七个项目在这里检索。

⑦ 对于输入中的每一项，`pairwise`产生一个包含该项和下一项的二元组——如果有下一项的话。Python ≥ 3.10 版本可用。

⑧ 建造一个能永远产生数字`7`的`repeat`发生器。

⑨ 一个`repeat`生成器可以通过传递`times`参数来限制:这里数字`8`将产生`4`次。

⑩ `repeat`的一个常见用法:在`map`中提供固定参数；这里它提供了`5`乘数。

在 `itertools`文档页面](https://fpy.li/17-13)中，`combinations`、`combinations_with_replacement`和`permutations`生成器函数与`product`一起被称为*组合学生成器*。`itertools.product`与剩余的*组合*功能也有密切关系，如[示例 17-21 所示。

##### 示例 17-21：组合生成器函数为每个输入项目生成多个值

```
>>> list(itertools.combinations('ABC',2))①[('A', 'B'), ('A', 'C'), ('B', 'C')] >>> list(itertools.combinations_with_replacement('ABC',2))②[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')] >>> list(itertools.permutations('ABC',2))③[('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] >>> list(itertools.product('ABC',repeat=2))④[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')]
```

① 来自`'ABC'`中项目的`len()==2`的所有组合；生成的元组中的项目排序是不相关的(它们可以是集合)。

② `'ABC'`中项目的`len()==2`的所有组合，包括重复项目的组合。

③ `'ABC'`中项目的`len()==2`的所有排列；生成的元组中的项目排序是相关的。

④ 来自`'ABC'`和`'ABC'`的笛卡尔积(那是`repeat=2`的效果)。

我们将在本节中介绍的最后一组生成器函数旨在生成输入可重复项中的所有项，但以某种方式进行了重新排列。这里有两个返回多个生成器的函数:`itertools.groupby`和`itertools.tee`。这个组中的另一个生成器函数，内置的`reversed`，是本节中唯一一个不接受任何 iterable 作为输入，而只接受序列作为输入的函数。这是有意义的:因为`reversed`将从最后到第一个产生项目，它只对已知长度的序列起作用。但它通过根据需要生成每个项目，避免了制作序列反向副本的成本。我将`itertools.product`函数与*合并*生成器一起放在表 17-3 中，因为它们都消耗一个以上的 iterable，而表 17-5 中的生成器都最多接受一个输入 iterable。

Table 17-5\. Rearranging generator functions

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| `itertools` | `groupby(it, key=None)` | 生成形式为`(key, group)`的二元组，其中`key`是分组标准，`group`是生成组中项目的生成器 |
| (内置) | `reversed(seq)` | 从`seq`以相反的顺序产出物品，从最后到第一；`seq`必须是一个序列或者实现了`__reversed__`的特殊方法 |
| `itertools` | `tee(it, n=2)` | 产生一组 *n* 个生成器，每个生成器独立产生输入 iterable 的项 |

示例 17-22 演示了`itertools.groupby`和`reversed`内置的用法。注意`itertools.groupby`假设输入 iterable 是按照分组标准排序的，或者至少条目是按照该标准进行聚类的——即使没有完全排序。技术评论家 Miroslav ediv 建议了这个用例:你可以按时间顺序对`datetime`对象进行排序，然后按`groupby`工作日得到一组周一的数据，接着是周二的数据，等等。，然后到下一周的星期一，以此类推。

##### 示例 17-22： `itertools.groupby`

```
>>> list(itertools.groupby('LLLLAAGGG'))①[('L', <itertools._grouper object at 0x102227cc0>), ('A', <itertools._grouper object at 0x102227b38>), ('G', <itertools._grouper object at 0x102227b70>)] >>> forchar,groupinitertools.groupby('LLLLAAAGG'):②... print(char,'->',list(group))...L -> ['L', 'L', 'L', 'L'] A -> ['A', 'A',] G -> ['G', 'G', 'G'] >>> animals=['duck','eagle','rat','giraffe','bear',... 'bat','dolphin','shark','lion']>>> animals.sort(key=len)③>>> animals['rat', 'bat', 'duck', 'bear', 'lion', 'eagle', 'shark', 'giraffe', 'dolphin'] >>> forlength,groupinitertools.groupby(animals,len):④... print(length,'->',list(group))...3 -> ['rat', 'bat'] 4 -> ['duck', 'bear', 'lion'] 5 -> ['eagle', 'shark'] 7 -> ['giraffe', 'dolphin'] >>> forlength,groupinitertools.groupby(reversed(animals),len):⑤... print(length,'->',list(group))...7 -> ['dolphin', 'giraffe'] 5 -> ['shark', 'eagle'] 4 -> ['lion', 'bear', 'duck'] 3 -> ['bat', 'rat'] >>>
```

① `groupby`产生`(key, group_generator)`的元组。

② 处理`groupby`生成器涉及嵌套迭代:在这种情况下，外部`for`循环和内部`list`构造函数。

③ 按长度对`animals`进行分类。

④ 再次循环`key`和`group`对，显示`key`并将`group`展开成`list`。

⑤ 这里`reverse`生成器从右到左迭代`animals`。

这个组中的最后一个生成器函数是`iterator.tee`，它有一个独特的行为:它从单个输入 iterable 生成多个生成器，每个生成器从输入中生成每一项。那些发电机可以独立消耗，如示例 17-23 所示。

##### 示例 17-23： `itertools.tee`产生多个生成器，每个生成器产生输入生成器的每一项

```
>>> list(itertools.tee('ABC'))
[<itertools._tee object at 0x10222abc8>, <itertools._tee object at 0x10222ac08>]
>>> g1, g2 = itertools.tee('ABC')
>>> next(g1)
'A'
>>> next(g2)
'A'
>>> next(g2)
'B'
>>> list(g1)
['B', 'C']
>>> list(g2)
['C']
>>> list(zip(*itertools.tee('ABC')))
[('A', 'A'), ('B', 'B'), ('C', 'C')]
```

请注意，本节中的几个示例使用了生成器函数的组合。这是这些函数的一个很大的特点:因为它们将生成器作为参数并返回生成器，所以它们可以以许多不同的方式组合。

现在我们将回顾标准库中另一组可迭代的函数。

# 可迭代的缩减函数

表 17-6 中的 函数都接受一个迭代并返回一个结果。它们被称为“减少”、“折叠”或“积累”功能。我们可以用`functools.reduce`实现这里列出的每一个内置，但是它们作为内置存在，因为它们更容易解决一些常见的用例。关于`functools.reduce`更长的解释出现在“Vector Take # 4:Hashing and a fast = =”。

在`all`和`any`的情况下，有一个重要的优化`functools.reduce`不支持:`all`和`any`短路——即一旦结果确定，它们就停止消耗迭代器。参见示例 17-24 中`any`的最后一次测试。

Table 17-6\. Built-in functions that read iterables and return single values

| 组件 | 功能 | 描述 |
| --- | --- | --- |
| (内置) | `all(it)` | 如果`it`中的所有项目都为真，则返回`True`，否则返回`False`；`all([])`返回`True` |
| (内置) | `any(it)` | 如果`it`中的任何一项为真，则返回`True`，否则返回`False`；`any([])`返回`False` |
| (内置) | `max(it, key=,] [default=])` | 返回`it`中各项的最大值； ^([a) `key`是一个排序函数，如`sorted`中；如果 iterable 为空，则返回`default` |
| (内置) | `min(it, key=,] [default=])` | 返回`it`中项目的最小值。 ^([b) `key`是一个排序函数，如`sorted`中；如果 iterable 为空，则返回`default` |
| `functools` | `reduce(func, it, [initial])` | 返回将`func`应用于第一对项目的结果，然后应用于该结果和第三个项目，依此类推；如果给定，`initial`与第一个项目形成初始对 |
| (内置) | `sum(it, start=0)` | `it`中所有项目的总和，加上可选的`start`值(添加浮动时使用`math.fsum`以获得更高的精度) |
| 也可称为`max(arg1, arg2, …, key=?])`，在这种情况下，返回参数中的最大值。^([b) 也可以称为`min(arg1, arg2, …, [key=?])`，在这种情况下返回自变量中的最小值。 |

`all`和`any`的操作在示例 17-24 中举例说明。

##### 示例 17-24：某些序列的`all`和`any`结果

```
>>> all([1,2,3])True >>> all([1,0,3])False >>> all([])True >>> any([1,2,3])True >>> any([1,0,3])True >>> any([0,0.0])False >>> any([])False >>> g=(nfornin[0,0.0,7,8])>>> any(g)①True >>> next(g)②8
```

① `any`迭代`g`直到`g`产生`7`；然后`any`停止，返回`True`。

② 这就是为什么`8`还在。

另一个接受 iterable 并返回其他内容的内置函数是`sorted`。与作为生成器函数的`reversed`不同，`sorted`构建并返回一个新的`list`。毕竟，输入 iterable 的每一项都必须被读取，这样它们才能被排序，而排序发生在一个`list`中，因此`sorted`只是在完成后返回那个`list`。我在这里提到`sorted`是因为它确实消耗了一个任意的 iterable。

当然，`sorted`和归约函数只对最终停止的迭代有效。否则，它们将继续收集项目，永远不会返回结果。

###### 注意

如果你已经读到这里，你已经看到了这一章最重要和最有用的内容。其余部分涵盖了我们大多数人不经常看到或不经常需要的高级生成器特性，比如`yield from`构造和经典协程。

还有关于类型提示可迭代程序、迭代器和经典协程的章节。

语法提供了一种组合生成器的新方法。那是下一个。

# 产量来自的子发电机

Python 3.3 中引入了`yield from`表达式 语法，允许生成器将工作委托给子生成器。

在引入`yield from`之前，当一个生成器需要产生另一个生成器产生的值时，我们使用`for`循环:

```
>>> def sub_gen():
...     yield 1.1
...     yield 1.2
...
>>> def gen():
...     yield 1
...     for i in sub_gen():
...         yield i
...     yield 2
...
>>> for x in gen():
...     print(x)
...
1
1.1
1.2
2
```

我们可以使用`yield from`得到相同的结果，正如你在示例 17-25 中看到的。

##### 示例 17-25：试驾`yield from`

```
>>> def sub_gen():
...     yield 1.1
...     yield 1.2
...
>>> def gen():
...     yield 1
...     yield from sub_gen()
...     yield 2
...
>>> for x in gen():
...     print(x)
...
1
1.1
1.2
2
```

在示例 17-25 中， `for`循环是*客户端代码*，`gen`是*委托生成器*，`sub_gen`是*子生成器*。注意`yield from`暂停`gen`，而`sub_gen`接管直到耗尽。由`sub_gen`产生的值通过`gen`直接传递给客户端`for`循环。同时，`gen`被挂起，看不到通过它的值。只有当`sub_gen`完成后，`gen`才恢复。

当子生成器包含一个带有值的`return`语句时，可以通过使用`yield from`作为表达式的一部分，在委托生成器中捕获该值。示例 17-26 演示。

##### 示例 17-26： `yield from`获取子生成器的返回值

```
>>> def sub_gen():
...     yield 1.1
...     yield 1.2
...     return 'Done!'
...
>>> def gen():
...     yield 1
...     result = yield from sub_gen()
...     print('<--', result)
...     yield 2
...
>>> for x in gen():
...     print(x)
...
1
1.1
1.2
<-- Done!
2
```

现在我们已经看到了`yield from`的基础知识，让我们研究几个简单但实用的用法示例。

## 改造链条

我们在表 17-3 中看到`itertools`提供了一个`chain`生成器，它从几个可迭代项中产生项，迭代第一个，然后第二个，依此类推直到最后一个。这是 Python 中嵌套了`for`循环的`chain`的自制实现: [10]

```
>>> def chain(*iterables):
...     for it in iterables:
...         for i in it:
...             yield i
...
>>> s = 'ABC'
>>> r = range(3)
>>> list(chain(s, r))
['A', 'B', 'C', 0, 1, 2]
```

前面代码中的`chain`生成器通过驱动内部`for`循环中的每个`it`依次委托给每个可迭代的`it`。这个内部循环可以用一个`yield from`表达式替换，如下一个控制台清单所示:

```
>>> def chain(*iterables):
...     for i in iterables:
...         yield from i
...
>>> list(chain(s, t))
['A', 'B', 'C', 0, 1, 2]
```

在这个例子中使用`yield from`是正确的，代码读起来更好，但它看起来像是语法糖，几乎没有真正的收获。现在让我们开发一个更有趣的例子。

## 穿过一棵树

在本节的中，我们将看到`yield from`在一个脚本中遍历一个树形结构。我会一步一步来。

这个例子的树结构是 Python 的[异常层次](https://fpy.li/17-14)。但是该模式可以适于显示目录树或任何其他树结构。

从零级的`BaseException`开始，从 Python 3.10 开始，异常层次结构有五级深。我们的第一步是显示零级。

给定一个根类，示例 17-27 中的`tree`生成器产生它的名字并停止。

##### 示例 17-27： tree/step0/tree.py:产生根类的名称并停止

```
def tree(cls):
    yield cls.__name__

def display(cls):
    for cls_name in tree(cls):
        print(cls_name)

if __name__ == '__main__':
    display(BaseException)
```

示例 17-27 的输出只有一行:

```
BaseException
```

下一步是第一步。`tree`生成器将产生根类的名称和每个直接子类的名称。子类的名称缩进显示层次结构。这是我们想要的输出:

```
$ python3 tree.py
BaseException
    Exception
    GeneratorExit
    SystemExit
    KeyboardInterrupt
```

示例 17-28 产生该输出。

##### 示例 17-28： tree/step1/tree.py:产生根类和直接子类的名称

```
deftree(cls):yieldcls.__name__,0①forsub_clsincls.__subclasses__():②yieldsub_cls.__name__,1③defdisplay(cls):forcls_name,levelintree(cls):indent=''*4*level④print(f'{indent}{cls_name}')if__name__=='__main__':display(BaseException)
```

① 为了支持缩进输出，生成类的名称及其在层次结构中的级别。

② 使用`__subclasses__`特殊方法获得子类的列表。

③ 产生子类和级别 1 的名称。

④ 构建`4`个空格乘以`level`的缩进字符串。在零级，这将是一个空字符串。

在示例 17-29 中，我重构了`tree`以将根类的特例从子类中分离出来，这现在由`sub_tree`生成器处理。在`yield from`处，`tree`发电机暂停，`sub_tree`接管生产值。

##### 示例 17-29： tree/step2/tree.py: `tree`产生根类名，然后委托给`sub_tree`

```
deftree(cls):yieldcls.__name__,0yield fromsub_tree(cls)①defsub_tree(cls):forsub_clsincls.__subclasses__():yieldsub_cls.__name__,1②defdisplay(cls):forcls_name,levelintree(cls):③indent=''*4*levelprint(f'{indent}{cls_name}')if__name__=='__main__':display(BaseException)
```

① 委托给`sub_tree`以产生子类的名称。

② 产生每个子类和级别 1 的名称。由于`tree`内的`yield from sub_tree(cls)`，这些值完全绕过了`tree`发生器功能…

③ …直接在这里接收。

按照循序渐进的方法，我将编写我能想到的最简单的代码来达到第二级。对于深度优先的](https://fpy.li/17-15)树遍历，在产生第 1 层中的每个节点之后，我想在恢复第 1 层之前产生第 2 层中该节点的子节点。一个嵌套的`for`循环会处理这个问题，如[示例 17-30 所示。

##### 示例 17-30： tree/step3/tree.py: `sub_tree`深度优先遍历级别 1 和级别 2

```
def tree(cls):
    yield cls.__name__, 0
    yield from sub_tree(cls)

def sub_tree(cls):
    for sub_cls in cls.__subclasses__():
        yield sub_cls.__name__, 1
        for sub_sub_cls in sub_cls.__subclasses__():
            yield sub_sub_cls.__name__, 2

def display(cls):
    for cls_name, level in tree(cls):
        indent = ' ' * 4 * level
        print(f'{indent}{cls_name}')

if __name__ == '__main__':
    display(BaseException)
```

这是运行示例 17-30 中 *step3/tree.py* 的结果:

```
$ python3 tree.py
BaseException
    Exception
        TypeError
        StopAsyncIteration
        StopIteration
        ImportError
        OSError
        EOFError
        RuntimeError
        NameError
        AttributeError
        SyntaxError
        LookupError
        ValueError
        AssertionError
        ArithmeticError
        SystemError
        ReferenceError
        MemoryError
        BufferError
        Warning
    GeneratorExit
    SystemExit
    KeyboardInterrupt
```

你可能已经知道这是怎么回事了，但是我将再一次坚持循序渐进:让我们通过添加另一个嵌套的`for`循环来达到第 3 级。程序的其余部分保持不变，因此示例 17-31 仅显示了`sub_tree`生成器。

##### 示例 17-31： `sub_tree`来自 *tree/step4/tree.py* 的生成器

```
def sub_tree(cls):
    for sub_cls in cls.__subclasses__():
        yield sub_cls.__name__, 1
        for sub_sub_cls in sub_cls.__subclasses__():
            yield sub_sub_cls.__name__, 2
            for sub_sub_sub_cls in sub_sub_cls.__subclasses__():
                yield sub_sub_sub_cls.__name__, 3
```

示例 17-31 中有一个清晰的模式。我们执行一个`for`循环来获得级别 *N* 的子类。每一次循环，我们产生一个层次 *N* 的子类，然后开始另一个`for`循环来访问层次 *N* +1。

在“改造链条”中，我们看到了如何用同一台发电机上的`yield from`替换驱动发电机的嵌套`for`循环。我们可以在这里应用这个想法，如果我们让`sub_tree`接受一个`level`参数，然后`yield from`递归地接受它，传递当前的子类作为下一级编号的新根类。参见示例 17-32 。

##### 示例 17-32： tree/step5/tree.py:递归`sub_tree`在内存允许的范围内

```
def tree(cls):
    yield cls.__name__, 0
    yield from sub_tree(cls, 1)

def sub_tree(cls, level):
    for sub_cls in cls.__subclasses__():
        yield sub_cls.__name__, level
        yield from sub_tree(sub_cls, level+1)

def display(cls):
    for cls_name, level in tree(cls):
        indent = ' ' * 4 * level
        print(f'{indent}{cls_name}')

if __name__ == '__main__':
    display(BaseException)
```

示例 17-32 可以遍历任意深度的树，只受 Python 的递归限制。默认限制允许 1，000 个挂起函数。

任何关于递归的好教程都会强调拥有一个基本用例以避免无限递归的重要性。基本情况是返回而不进行递归调用的条件分支。基本情况通常用一个`if`语句来实现。在示例 17-32 中，`sub_tree`没有`if`，但是在`for`循环中有一个隐含的条件:如果`cls.__subclasses__()`返回一个空列表，则循环体不被执行，因此不会发生递归调用。基本情况是当`cls`类没有子类时。在这种情况下，`sub_tree`不会产生任何结果。它只是返回。

示例 17-32 如预期的那样工作，但是我们可以通过回忆我们到达第三级时观察到的模式使它更简洁(示例 17-31 ):我们产生一个具有第 *N* 级的子类，然后开始一个嵌套的 for 循环来访问第 *N* +1 级。在示例 17-32 中，我们用`yield from`替换了那个嵌套循环。现在我们可以将`tree`和`sub_tree`合并成一个生成器。示例 17-33 是本例的最后一步。

##### 示例 17-33：tree/step 6/tree . py:`tree`的递归调用传递一个递增的`level`参数

```
def tree(cls, level=0):
    yield cls.__name__, level
    for sub_cls in cls.__subclasses__():
        yield from tree(sub_cls, level+1)

def display(cls):
    for cls_name, level in tree(cls):
        indent = ' ' * 4 * level
        print(f'{indent}{cls_name}')

if __name__ == '__main__':
    display(BaseException)
```

在“yield from的子生成器”的开始，我们看到了`yield from`如何绕过委托生成器，将子生成器直接连接到客户端代码。当生成器被用作协同程序时，这种联系就变得非常重要，它不仅产生而且消费来自客户端代码的值，我们将在“经典协同程序”中看到。

在第一次接触`yield from`之后，让我们转向类型提示可迭代对象和迭代器。

# 泛型可迭代类型

Python 的 标准库有很多接受可迭代参数的函数。在你的代码中，这样的函数可以像我们在示例 8-15](ch08.xhtml#replacer_ex) 中看到的`zip_replace`函数一样使用`collections.abc.Iterable`进行注释(或者`typing.Iterable`，如果你必须支持 Python 3.8 或更早版本，如“遗留支持和不推荐的集合类型”中所解释)。参见[示例 17-34 。

##### 示例 17-34： replacer.py 返回字符串元组的迭代器

```
fromcollections.abcimportIterableFromTo=tuple[str,str]①defzip_replace(text:str,changes:Iterable[FromTo])->str:②forfrom_,toinchanges:text=text.replace(from_,to)returntext
```

① 定义类型别名；不是必需的，但是使下一个类型提示更具可读性。从 Python 3.10 开始，`FromTo`应该有一个`typing.TypeAlias`的类型提示来阐明这行的原因:`FromTo: TypeAlias = tuple[str, str]`。

② 注释`changes`以接受一个`FromTo`元组的`Iterable`。

`Iterator`类型不像`Iterable`类型那样经常出现，但也很容易写。示例 17-35 展示了熟悉的斐波纳契生成器，并做了注释。

##### 示例 17-35： *fibo_gen.py* : `fibonacci`返回整数生成器

```
from collections.abc import Iterator

def fibonacci() -> Iterator[int]:
    a, b = 0, 1
    while True:
        yield a
        a, b = b, a + b
```

注意，类型`Iterator`用于用`yield`编码为函数的生成器，以及用`__next__`“手工”编写为类的迭代器。还有一种`collections.abc.Generator`类型(以及相应的不推荐使用的`typing.Generator`)我们可以用来注释生成器对象，但是对于作为迭代器使用的生成器来说，这是不必要的冗长。

示例 17-36 ，当用 Mypy 检查时，揭示了`Iterator`类型实际上是`Generator`类型的简化特例。

##### 示例 17-36： itergentype.py:注释迭代器的两种方法

```
fromcollections.abcimportIteratorfromkeywordimportkwlistfromtypingimportTYPE_CHECKINGshort_kw=(kforkinkwlistiflen(k)<5)①ifTYPE_CHECKING:reveal_type(short_kw)②long_kw:Iterator[str]=(kforkinkwlistiflen(k)>=4)③ifTYPE_CHECKING:④reveal_type(long_kw)
```

① 生成少于`5`字符的 Python 关键字的生成器表达式。

② Mypy 推断:`typing.Generatorbuiltins.str*, None, None]`。 ^([11)

③ 这也会产生字符串，但是我添加了一个显式的类型提示。

④ 透露类型:`typing.Iterator[builtins.str]`。

`abc.Iteratorstr]`与 `abc.Generator[str, None, None]`一致，因此 Mypy 在[示例 17-36 中没有发出类型检查错误。

`Iterator[T]`是`Generator[T, None, None]`的快捷方式。这两个注释都意味着“一个生成类型为`T`的项的生成器，但是它不消费也不返回值。”能够消费和返回值的生成器是协程，我们的下一个主题。

# 经典协程

###### 注意

[PEP 342——通过增强的生成器生成协同程序](https://fpy.li/pep342)引入了`.send()`和其他特性，使得将生成器用作协同程序成为可能。PEP 342 使用了“协同程序”这个词，它的意思和我在这里使用的一样。

不幸的是，Python 的官方文档和标准库现在使用不一致的术语来指代作为协程使用的生成器，这迫使我采用“经典协程”限定词来与较新的“本机协程”对象形成对比。

Python 3.5 出来后，趋势是用“协程”作为“原生协程”的同义词。但是 PEP 342 没有被弃用，经典的协程仍然像最初设计的那样工作，尽管它们不再被`asyncio`支持。

理解 Python 中的经典协程令人困惑，因为它们实际上是以不同方式使用的生成器。因此，让我们回过头来考虑 Python 的另一个特性，它有两种用途。

我们在“元组不仅仅是不可变列表”中看到，我们可以使用`tuple`实例作为记录或不可变序列。当用作记录时，一个元组被期望具有特定数量的项，并且每个项可以具有不同的类型。当用作不可变列表时，一个元组可以具有任意长度，并且所有的项都应该具有相同的类型。这就是为什么有两种不同的方式用类型提示来注释元组:

```
# A city record with name, country, and population:
city: tuple[str, str, int]

# An immutable sequence of domain names:
domains: tuple[str, ...]
```

发电机也有类似的情况。它们通常用作迭代器，但也可以用作协程。一个*协程*实际上是一个生成器函数，在其主体中使用 `yield`关键字创建。并且 *协程对象*在物理上是生成器对象。尽管在 C 语言中共享相同的底层实现，但 Python 中生成器和协程的用例是如此不同，以至于有两种方法可以对它们进行类型提示:

```
# The `readings` variable can be bound to an iterator
# or generator object that yields `float` items:
readings: Iterator[float]

# The `sim_taxi` variable can be bound to a coroutine
# representing a taxi cab in a discrete event simulation.
# It yields events, receives `float` timestamps, and returns
# the number of trips made during the simulation:
sim_taxi: Generator[Event, float, int]
```

更令人困惑的是，`typing`模块作者决定将该类型命名为`Generator`，而事实上它描述了一个生成器对象的 API，该对象旨在用作协程，而生成器更经常被用作简单的迭代器。

[`typing`文档](https://fpy.li/17-17)是这样描述`Generator`的形参的:

```
Generator[YieldType, SendType, ReturnType]
```

`SendType`仅在发电机用作协程时相关。那个类型参数就是调用`gen.send(x)`中`x`的类型。在被编码为表现为迭代器而不是协程的生成器上调用`.send()`是错误的。同样，`ReturnType`只对注释协程有意义，因为迭代器不像常规函数那样返回值。在作为迭代器的生成器上，唯一明智的操作是通过`for`循环和其他形式的迭代直接或间接调用`next(it)`。`YieldType`是调用`next(it)`返回的值的类型。

`Generator`类型与 [`typing.Coroutine`](https://fpy.li/typecoro) 类型参数相同:

```
Coroutine[YieldType, SendType, ReturnType]
```

[`typing.Coroutine`文档](https://fpy.li/typecoro)实际上是说:“类型变量的方差和阶数对应于`Generator`的方差和阶数。”但是`typing.Coroutine`(已弃用)和`collections.abc.Coroutine`(从 Python 3.9 开始通用)只打算注释本地协程，而不是经典协程。如果您想在经典协程中使用类型提示，那么您会因为将它们标注为`Generator[YieldType, SendType, ReturnType]`而感到困惑。

David Beazley 创建了一些关于经典协程的最佳讲座和最全面的研讨会。在他的 [PyCon 2009 课程讲义](https://fpy.li/17-18)中，他有一张题为“保持直线”的幻灯片，上面写着:

> *   生成器为迭代生成数据
>     
>     
> *   协程是数据的消费者
>     
>     
> *   为了防止你的大脑爆炸，不要把这两个概念混在一起
>     
>     
> *   协同程序与迭代无关
>     
>     
> *   注意:让“收益”在一个协同过程中产生一个值是有用处的，但是它并不与迭代相关联。 [12]

现在让我们看看经典的验尸官是如何工作的。

## 示例:计算运行平均值的公式

当 在第 9 章](ch09.xhtml#closures_and_decorators)中讨论闭包时，我们研究对象来计算运行平均值。示例 9-7 显示了一个类，示例 9-13 显示了一个更高阶的函数，该函数返回了一个在闭包中跨调用保持`total`和`count`变量的函数。示例 17-37 说明了如何使用验尸官进行同样的操作。 ^([13)

##### 示例 17-37：验尸官:计算运行平均值的验尸官

```
fromcollections.abcimportGeneratordefaverager()->Generator[float,float,None]:①total=0.0count=0average=0.0whileTrue:②term=yieldaverage③total+=termcount+=1average=total/count
```

① 该函数返回产生`float`值的生成器，通过`.send()`接受`float`值，但不返回有用的值。 [14]

② 这个无限循环意味着只要客户端代码发送值，coroutine 就会继续产生平均值。

③ 这里的`yield`语句挂起协同程序，向客户端产生一个结果，然后——稍后——获取调用者发送给协同程序的一个值，开始无限循环的另一次迭代。

在协同程序中，`total`和`count`可以是局部变量:当协同程序暂停等待下一个`.send()`时，不需要实例属性或闭包来保持上下文。这就是为什么 coroutines 是异步编程中回调的有吸引力的替代品——它们在激活之间保持本地状态。

示例 17-38 进行 doctests 以显示`averager`协同作用。

##### 示例 17-38：验尸官 py:对示例 17-37 中的运行平均验尸官进行 doctest

```
>>>coro_avg=averager()①>>>next(coro_avg)②0.0>>>coro_avg.send(10)③10.0>>>coro_avg.send(30)20.0>>>coro_avg.send(5)15.0
```

① 创建协同对象。

② 启动验尸官。这样就得到`average`的初始值:0.0。

③ 现在我们进入正题:对`.send()`的每次调用产生当前平均值。

在示例 17-38 中，调用`next(coro_avg)`使协程前进到`yield`，为`average`产生初始值。您还可以通过调用`coro_avg.send(None)`来启动协程——这实际上是`next()`内置的功能。但是你不能发送除了`None`以外的任何值，因为协程只有在`yield`行暂停时才能接受一个发送的值。调用`next()`或`.send(None)`前进到第一个`yield`被称为“启动协程”

每次激活后，协程精确地在 `yield`关键字处暂停，等待发送一个值。行`coro_avg.send(10)`提供该值，导致协程激活。`yield`表达式解析为值 10，将其赋给`term`变量。循环的其余部分更新`total`、`count`和`average`变量。在`while`循环中的下一次迭代产生`average`，协程再次在`yield`关键字处挂起。

细心的读者可能急于知道如何终止一个`averager`实例(例如`coro_avg`)的执行，因为它的主体是一个无限循环。我们通常不需要终止生成器，因为一旦不再有对它的有效引用，它就会被垃圾收集。如果需要显式终止，使用`.close()`方法，如示例 17-39 所示。

##### 示例 17-39： coroaverager.py:上接示例 17-38

```
>>>coro_avg.send(20)①16.25>>>coro_avg.close()②>>>coro_avg.close()③>>>coro_avg.send(5)④Traceback(mostrecentcalllast):...StopIteration
```

① `coro_avg`是示例 17-38 中创建的实例。

② `.close()`方法在挂起的`yield`表达式处引发`GeneratorExit`。如果没有在协程函数中处理，异常将终止它。被包装协程的生成器对象捕获——这就是为什么我们看不到它。

③ 在先前关闭的协程上调用`.close()`没有任何效果。

④ 在关闭的协程上尝试`.send()`会引发`StopIteration`。

除了`.send()`方法，[PEP 342-通过增强生成器的协同程序](https://fpy.li/pep342)还引入了一种协同程序返回值的方法。下一节将展示如何操作。

## 从协程中返回值

我们现在将研究另一个计算平均值的协程。这个版本不会产生部分结果。相反，它返回一个包含项数和平均值的元组。我将清单分成两部分:示例 17-40 和示例 17-41 。

##### 示例 17-40： coroaverager2.py:文件顶部

```
fromcollections.abcimportGeneratorfromtypingimportUnion,NamedTupleclassResult(NamedTuple):①count:int# type: ignore ②average:floatclassSentinel:③def__repr__(self):returnf'<Sentinel>'STOP=Sentinel()④SendType=Union[float,Sentinel]⑤
```

① 示例 17-41 中的`averager2`协程将返回一个`Result`的实例。

② `Result`实际上是`tuple`的子类，它有一个我不需要的`.count()`方法。`# type: ignore`注释防止 Mypy 抱怨有一个`count`字段。 [15]

③ 用可读的`__repr__`生成标记值的类。

④ 我将使用 sentinel 值让协程停止收集数据并返回结果。

⑤ 我将把这个类型别名用于协程`Generator`返回类型的第二个类型参数，即`SendType`参数。

`SendType`定义在 Python 3.10 中也有效，但如果不需要支持更早的版本，不如这样写，从导入`TypeAlias`后`typing` :

```
SendType: TypeAlias = float | Sentinel
```

使用`|`而不是`typing.Union`是如此的简洁和易读，以至于我可能不会创建那个类型别名，但是我会这样写`averager2`的签名:

```
def averager2(verbose: bool=False) -> Generator[None, float | Sentinel, Result]:
```

现在，让我们研究一下协程代码本身(示例 17-41 )。

##### 示例 17-41： coroaverager2.py:返回结果值的协同程序

```
defaverager2(verbose:bool=False)->Generator[None,SendType,Result]:①total=0.0count=0average=0.0whileTrue:term=yield②ifverbose:print('received:',term)ifisinstance(term,Sentinel):③breaktotal+=term④count+=1average=total/countreturnResult(count,average)⑤
```

① 对于这个协程，产出类型是`None`，因为它不产生数据。它接收`SendType`的数据，并在完成时返回一个`Result`元组。

② 像这样使用`yield`只有在协程中才有意义，协程被设计用来消费数据。这产生了`None`，但是从`.send(term)`接收了一个`term`。

③ 如果`term`是一个`Sentinel`，从循环中断开。多亏了这张`isinstance`支票…

④ …Mypy 允许我将`term`添加到`total`中，而不会标记一个错误，即我不能将`float`添加到可能是`float`或`Sentinel`的对象中。

⑤ 只有当一个`Sentinel`被发送到协程时，才会到达该行。

现在让我们看看如何使用这个协程，从一个实际上不产生结果的简单例子开始( Example 17-42 )。

##### 示例 17-42： coroaverager2.py: doctest 显示`.cancel()`

```
>>>coro_avg=averager2()>>>next(coro_avg)>>>coro_avg.send(10)①>>>coro_avg.send(30)>>>coro_avg.send(6.5)>>>coro_avg.close()②
```

① 回想一下`averager2`不会产生部分结果。它产生了`None`，Python 的控制台省略了它。

② 在这个协程中调用`.close()`会使其停止，但不会返回结果，因为`GeneratorExit`异常是在协程的`yield`行引发的，所以永远不会到达`return`语句。

现在让我们在示例 17-43 中使用它。

##### 示例 17-43： coroaverager2.py: doctest 显示带有`Result`的`StopIteration`

```
>>>coro_avg=averager2()>>>next(coro_avg)>>>coro_avg.send(10)>>>coro_avg.send(30)>>>coro_avg.send(6.5)>>>try:...coro_avg.send(STOP)①...exceptStopIterationasexc:...result=exc.value②...>>>result③Result(count=3,average=15.5)
```

① 发送`STOP` sentinel 使协程从循环中脱离并返回一个`Result`。包装协程的生成器对象然后引发`StopIteration`。

② `StopIteration`实例有一个`value`属性绑定到终止协程的`return`语句的值。

③ 信不信由你！

这种从包装在`StopIteration`异常中的协程中“走私”返回值的想法是一种奇怪的黑客行为。尽管如此，这种奇怪的黑客行为是 [PEP 342 的一部分——通过增强生成器](https://fpy.li/pep342)的协同程序，并且在 [`StopIteration`异常](https://fpy.li/17-22)和[*的第 6 章*](https://fpy.li/17-24)部分的【产出表达式】中记录了 Python 语言参考 。

委托生成器可以使用`yield from`语法直接获得协程的返回值，如示例 17-44 所示。

##### 示例 17-44： coroaverager2.py: doctest 显示带有`Result`的`StopIteration`

```
>>>defcompute():...res=yield fromaverager2(True)①...print('computed:',res)②...returnres③...>>>comp=compute()④>>>forvin[None,10,20,30,STOP]:⑤...try:...comp.send(v)⑥...exceptStopIterationasexc:⑦...result=exc.valuereceived:10received:20received:30received:<Sentinel>computed:Result(count=3,average=20.0)>>>result⑧Result(count=3,average=20.0)
```

① `res`将收集`averager2`的返回值；`yield from`机制在处理标志协程终止的`StopIteration`异常时检索返回值。当`True`时，`verbose`参数使协程打印接收到的值，使其操作可见。

② 这台发电机运转时，请注意这条线路的输出。

③ 返回结果。这个也会被包裹在`StopIteration`里。

④ 创建委托协程对象。

⑤ 这个循环将驱动委托协程。

⑥ 发送的第一个值是`None`，用于初始化协程；最后是哨兵阻止了它。

⑦ 捕捉`StopIteration`以获取`compute`的返回值。

⑧ 在由`averager2`和`compute`输出的行之后，我们得到了`Result`实例。

尽管这里的例子做的不多，但是代码很难理解。用`.send()`调用驱动协程并检索结果是复杂的，除了用`yield from`——但是我们只能在委托生成器/协程中使用该语法，它最终必须由一些重要的代码驱动，如示例 17-44 所示。

前面的例子表明，直接使用协程既麻烦又混乱。添加异常处理和协程`.throw()`方法，示例变得更加复杂。我不会在本书中讨论`.throw()`，因为——像`.send()`一样——它只对“手动”驱动协程有用，但是我不建议这样做，除非你正在从头开始创建一个新的基于协程的框架。

###### 注意

如果你对经典协同程序的更深入的报道感兴趣——包括`.throw()`方法——请在[*fluentpython.com*](http://fluentpython.com)伙伴网站查看[“经典协同程序”](https://fpy.li/oldcoro)。这篇文章包括类似 Python 的伪代码，详细说明了`yield from`如何驱动生成器和协同程序，以及一个小型离散事件模拟，演示了在没有异步编程框架的情况下使用协同程序的一种并发形式。

在实践中，协同程序的有效工作需要一个专门的框架的支持。这就是`asyncio`在 Python 3.3 中为经典协程提供的功能。随着 Python 3.5 中本地协程的出现，Python 核心开发人员正在逐步淘汰对经典协程的支持。但是基本的机制非常相似。`async def`语法使得本地协程更容易在代码中发现，这是一个很大的好处。在内部，本机协同程序使用`await`而不是`yield from`来委托给其他协同程序。第二十一章就是这么回事。

现在让我们用一个令人费解的章节来结束这一章，它是关于协程类型提示中的协变和逆变的。

## 经典协程的泛型类型提示

回到 在“逆变类型”中，我提到过`typing.Generator`是为数不多的带有逆变类型参数的标准库类型。既然我们已经学习了经典的协程，我们就可以理解这个泛型类型了。

下面是`typing.Generator`是如何在 Python 3.6 的 *typing.py* 模块中 [16] 声明的

```
T_co = TypeVar('T_co', covariant=True)
V_co = TypeVar('V_co', covariant=True)
T_contra = TypeVar('T_contra', contravariant=True)

# many lines omitted

class Generator(Iterator[T_co], Generic[T_co, T_contra, V_co],
                extra=_G_base):
```

泛型类型声明意味着`Generator`类型提示需要我们之前见过的三个类型参数:

```
my_coro : Generator[YieldType, SendType, ReturnType]
```

从形参中的类型变量我们看到`YieldType`和`ReturnType`是协变的，而`SendType`是逆变的。为了理解为什么，考虑一下`YieldType`和`ReturnType`是“输出”类型。两者都描述来自协程对象的数据——即，当作为协程对象使用时的生成器对象。

这些是协变的是有意义的，因为任何期望协程产生浮点数的代码都可以使用产生整数的协程。这就是为什么`Generator`在其`YieldType`参数上是协变的。同样的推理也适用于`ReturnType`参数—也是协变的。

使用“协变类型”中介绍的符号，第一个和第三个参数的协方差由指向同一方向的`:>`符号表示:

```
                       float :> int
Generator[float, Any, float] :> Generator[int, Any, int]
```

`YieldType`和`ReturnType`是“方差经验法则”的第一个规则的例子:

> 1.  如果形式类型参数为来自对象的数据定义了一种类型，那么它可以是协变的。

另一方面，`SendType`是一个“输入”参数:它是协程对象的`.send(value)`方法的`value`参数的类型。需要向协程发送浮点的客户端代码不能使用将`int`作为`SendType`的协程，因为`float`不是`int`的子类型。换句话说，`float`与 `int`并不一致。但是客户端可以使用一个带有`complex`的协程作为`SendType`，因为`float`是`complex`的一个子类型，因此`float`与*一致——与* `complex`一致。

`:>`符号使第二个参数的逆变可见:

```
                     float :> int
Generator[Any, float, Any] <: Generator[Any, int, Any]
```

这是第二个方差法则的一个例子:

> 2.  如果一个形式类型参数为数据定义了一个类型，而这个数据在最初构造之后进入对象，那么它可能是逆变的。

这个关于方差的有趣讨论完成了这本书最长的一章。

# 章节摘要

迭代 在语言中是如此的根深蒂固，以至于我喜欢说 Python 搜索迭代器。Python 语义中迭代器模式的集成是设计模式并不适用于所有编程语言的一个典型例子。在 Python 中，如示例 17-4 中“手动”实现的经典迭代器没有实际用途，除非作为一个教学示例。

在这一章中，我们构建了一个类的几个版本来迭代可能很长的文本文件中的单个单词。我们看到 Python 如何使用内置的`iter()`从类似序列的对象创建迭代器。我们用`__next__()`构建了一个经典的迭代器作为类，然后我们使用生成器使`Sentence`类的每次连续重构更加简洁易读。

然后，我们编写了一个算术级数生成器，并展示了如何利用`itertools`模块来简化它。接下来是标准库中大多数通用生成器函数的概述。

然后，我们用`chain`和`tree`例子研究了简单生成器环境中的`yield from`表达式。

最后一个主要部分是关于经典协程的，在 Python 3.5 中添加了原生协程之后，这个主题的重要性逐渐减弱。尽管在实践中很难使用，但经典协程是本机协程的基础，而`yield from`表达式是`await`的直接前身。

还包括了对`Iterable`、`Iterator`和`Generator`类型的类型提示——后者提供了逆变类型参数的一个具体而罕见的例子。

# 进一步阅读

关于 发电机的详细技术说明，见*【6 . 2 . 9】中的 Python 语言参考*。屈服表情"。定义发生器功能的 PEP 是[PEP 255——简单发生器](https://fpy.li/pep255)。

[`itertools`模块文档](https://fpy.li/17-28)非常出色，因为包含了所有示例。尽管该模块中的函数是用 C 实现的，但文档显示了其中一些函数是如何用 Python 编写的，通常是通过利用模块中的其他函数。使用例子也很棒；例如，有一个片段展示了如何使用`accumulate`函数来分期偿还一笔贷款的利息，给定一段时间内的付款列表。还有一个[“ITER tools Recipes”](https://fpy.li/17-29)部分，它具有额外的高性能函数，这些函数使用`itertools`函数作为构建块。

除了 Python 的标准库，我推荐 [More Itertools](https://fpy.li/17-30) 包，它遵循优良的`itertools`传统，提供了强大的生成器，并提供了大量的例子和一些有用的方法。

第 3 版 *Python 指南*的第 4 章，“迭代器和生成器”。，由大卫·比兹利和布莱恩·k·琼斯(奥莱利)编写，有 16 个食谱，从许多不同的角度涵盖了这个主题，侧重于实际应用。它包括一些带有`yield from`的启发性食谱。

sebastian Rittau——目前是*排版*的顶级撰稿人——解释了迭代器为什么应该是可迭代的，正如他在 2006 年指出的那样，[“Java:迭代器是不可迭代的”](https://fpy.li/17-31)。

`yield from`语法在 [PEP 380 的“Python 3.3 中的新特性”一节中有示例解释——委托给子生成器](https://fpy.li/17-32)的语法。我的帖子[【经典协同程序】](https://fpy.li/oldcoro)在[*fluentpython.com*](http://fluentpython.com)对`yield from`进行了深入的解释，包括用 c 语言实现的 Python 伪代码

David Beazley 是 Python 生成器和协程的最高权威。 *[巨蟒食谱](https://fpy.li/pycook3)* ，第 3 版。(O'Reilly)他与布莱恩·琼斯合著了许多关于协同程序的食谱。Beazley 关于这个主题的 PyCon 教程以其深度和广度而闻名。第一次是在 PyCon US 2008: [“系统程序员的生成器技巧”](https://fpy.li/17-33)。PyCon US 2009 看到了传说中的[“一个关于协同程序和并发性的奇怪课程”](https://fpy.li/17-34)(很难找到所有三个部分的视频链接:[第 1 部分](https://fpy.li/17-35)、[第 2 部分](https://fpy.li/17-36)和[第 3 部分](https://fpy.li/17-37))。他在蒙特利尔 PyCon 2014 上的教程是[“生成器:最后的边界”](https://fpy.li/17-38)，其中他处理了更多的并发示例——所以它实际上更多的是关于第 21 章中的主题。Dave 无法抗拒在他的课上让大脑爆炸，所以在“最后的边界”的最后一部分，协程在算术表达式计算器中取代了经典的访问者模式。

协程允许以新的方式组织代码，就像递归或多态(动态调度)一样，需要一些时间来适应它们的可能性。用协程重写经典算法的一个有趣的例子是 James Powell 的文章[“用协程重写贪婪算法”](https://fpy.li/17-39)。

布雷特·斯拉特金的 [*有效 Python* ，第 1 版。(Addison-Wesley)有一个精彩的简短章节，标题是“考虑协程并发运行许多功能”那一章不在*有效 Python* 第二版里，但网上还是有](https://fpy.li/17-40)[作为样本章](https://fpy.li/17-41)。Slatkin 展示了我见过的用`yield from`驱动协程的最好例子:John Conway 的[生命游戏](https://fpy.li/17-42)的实现，其中协程在游戏运行时管理每个单元的状态。我重构了生命游戏示例的代码——将实现游戏的函数和类与 Slatkin 原始代码中使用的测试片段分离开来。我还将测试重写为 doctests，这样您就可以在不运行脚本的情况下看到各种协程和类的输出。[重构后的示例](https://fpy.li/17-43)作为 [GitHub 要点](https://fpy.li/17-44)发布。

[1] 出自[【书呆子的复仇】](https://fpy.li/17-1)，一篇博文。

[2] 我们首先在“Vector Take # 1:Vector 2d 兼容”中使用了`reprlib`。

感谢科技评论人莱昂纳多·罗凯尔提供的这个好例子。

在回顾这段代码时，Alex Martelli 建议这个方法的主体可以简单地称为`return iter(self.words)`。他是对的:调用`self.words.__iter__()`的结果也将是一个迭代器，这是应该的。然而，我在这里使用了一个带有`yield`的`for`循环来介绍生成器函数的语法，这需要`yield`关键字，我们将在下一节中看到。在评论这本书的第二版时，莱昂纳多·罗凯尔为`__iter__`的正文建议了另一个捷径:`yield from self.words`。我们还将在本章后面介绍`yield from`。

[5] 有时我在给生成器函数命名时会加一个`gen`前缀或后缀，但这并不是常见的做法。当然，如果你正在实现一个 iterable，你不能这样做:必要的特殊方法必须被命名为`__iter__`。

[6] 感谢 David Kwast 提出这个例子。

[7] 在 Python 2 中，曾经有一个`coerce()`内置函数，但在 Python 3 中已经没有了。它被认为是不必要的，因为数字强制规则隐含在算术运算符方法中。因此，我所能想到的使初始值与系列中的其他值具有相同类型的最佳方法是执行加法，并使用其类型来转换结果。我在 Python-list 中询问了这个问题，并从 Steven D'Aprano 那里得到了一个极好的[回复。](https://fpy.li/17-11)

[8][*Fluent Python*代码库](https://fpy.li/code)中的 *17-it-generator/* 目录包含了 doctests 和一个脚本 *aritprog_runner.py* ，它针对 *aritprog*的所有变体运行测试。py* 脚本。

[9] 这里，术语“映射”与字典无关，但与`map`内置有关。

[10] `chain`和大部分`itertools`函数都是用 c 写的

[11] 从 0.910 版本开始，Mypy 仍然使用不推荐使用的`typing`类型。

[12] 幻灯片 33，“保持直线”，在[“一个关于协程和并发的好奇课程”](https://fpy.li/17-18)。

[13] 这个例子的灵感来自于 Python-ideas 列表中 Jacob Holm 的一个片段，消息标题为[“Yield-From:Finalization guaranties”](https://fpy.li/17-20)。一些变化出现在后面的帖子中，Holm 在[消息 003912](https://fpy.li/17-21) 中进一步解释了他的想法。

[14] 事实上，除非某个异常打破循环，否则它永远不会返回。Mypy 0.910 同时接受`None`和`typing​.NoReturn`作为生成器返回类型参数——但是它也在那个位置接受`str`，所以显然它现在不能完全分析协程代码。

[15] 我考虑过重命名字段，但`count`是协程中局部变量的最佳名称，也是我在书中类似例子中为该变量使用的名称，因此在`Result`字段中使用相同的名称是有意义的。当提交给工具会使代码变得更糟或不必要的复杂时，我会毫不犹豫地使用`# type: ignore`来避免静态类型检查器的限制和烦恼。

[16] 由于 Python 3.7、`typing.Generator`和其他对应于`collections.abc`中的 ABC 的类型被用相应 ABC 的包装器重构，所以它们的泛型参数在 *typing.py* 源文件中不可见。这也是我在这里引用 Python 3.6 源代码的原因。

[17] 按照[行话文件](https://fpy.li/17-26)的说法，去 *grok* 不仅仅是为了学习某样东西，而是为了吸收它，这样“它就成为你的一部分，你身份的一部分”

[18] 伽马 et。艾尔。，*设计模式:可复用面向对象软件的要素*，第 261 页。

代码在 Python 2 中，因为它的可选依赖项之一是一个名为*布吕马*的 Java 库，我们可以在用 Jython 运行脚本时导入它 Jython 还不支持 Python 3。

[20] 用于读取复合体的库*。mst* 二进制实际上是用 Java 编写的，所以这个功能只有在用 Jython 解释器(版本 2.5 或更新)执行 *isis2json.py* 时才可用。有关更多详细信息，请参见存储库中的 [*README.rst*](https://fpy.li/17-47) 文件。依赖项被导入到需要它们的生成器函数中，因此即使只有一个外部库可用，脚本也可以运行。**